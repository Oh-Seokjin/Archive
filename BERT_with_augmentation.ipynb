{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a35cfb1a0e6409a9bc4c4ab977d7da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_807bc0806d1c45479f3c69258d9d91e7",
              "IPY_MODEL_ed0b4a92702342dcbb3b44d8fc34aff6",
              "IPY_MODEL_0af0a19f720c49bc8583380d29ee85ec"
            ],
            "layout": "IPY_MODEL_863c3a07aff846699aed277ff81ede52"
          }
        },
        "807bc0806d1c45479f3c69258d9d91e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d5725f70e144770ae78191c54e42e8b",
            "placeholder": "​",
            "style": "IPY_MODEL_2a22d1c0963a468f8c96e8a095dd72e7",
            "value": ""
          }
        },
        "ed0b4a92702342dcbb3b44d8fc34aff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d7969b214474991a03bac1615f1ec01",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_767e568150414d8ab5ecd1f2318505e4",
            "value": 0
          }
        },
        "0af0a19f720c49bc8583380d29ee85ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61d7ba7c334b403f87112aad64f3b7e1",
            "placeholder": "​",
            "style": "IPY_MODEL_1761d37b4b7c47b1bb89f1254b3f9d43",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "863c3a07aff846699aed277ff81ede52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d5725f70e144770ae78191c54e42e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a22d1c0963a468f8c96e8a095dd72e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d7969b214474991a03bac1615f1ec01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "767e568150414d8ab5ecd1f2318505e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61d7ba7c334b403f87112aad64f3b7e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1761d37b4b7c47b1bb89f1254b3f9d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "premium"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oh-Seokjin/Text_Classifier_goorm/blob/main/BERT_with_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import requirements"
      ],
      "metadata": {
        "id": "TH32rzgprvgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "G9EvC1HBuf41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b5e12b4-477e-40a2-828d-135e00ae9930"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch_pretrained_bert"
      ],
      "metadata": {
        "id": "SkLixLsaV27z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7129ddd-fba0-49b3-dd08-32c70dde002e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2022.6.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.24.84)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.64.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.1.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.6.0)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.0.1)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.84 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.27.84)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.84->boto3->pytorch_pretrained_bert) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.84->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.84->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wandb"
      ],
      "metadata": {
        "id": "O3WquFBlibza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7c7b60-d091-4e5e-bac1-e97e8dd5113c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.13.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.9)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.9.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "vP_WwAXEigXq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4fc65a0-c8b2-4372-dcc6-43248365cb65"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mohseokjin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pdb\n",
        "import argparse\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "from collections import defaultdict\n",
        "import math\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from transformers import (\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        "    AutoConfig,\n",
        "    AdamW\n",
        ")\n",
        "\n",
        "from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule"
      ],
      "metadata": {
        "id": "AAdLxrUZrvgP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "1a35cfb1a0e6409a9bc4c4ab977d7da9",
            "807bc0806d1c45479f3c69258d9d91e7",
            "ed0b4a92702342dcbb3b44d8fc34aff6",
            "0af0a19f720c49bc8583380d29ee85ec",
            "863c3a07aff846699aed277ff81ede52",
            "2d5725f70e144770ae78191c54e42e8b",
            "2a22d1c0963a468f8c96e8a095dd72e7",
            "8d7969b214474991a03bac1615f1ec01",
            "767e568150414d8ab5ecd1f2318505e4",
            "61d7ba7c334b403f87112aad64f3b7e1",
            "1761d37b4b7c47b1bb89f1254b3f9d43"
          ]
        },
        "outputId": "a9556832-3e64-4b84-8db5-c68594d2e479"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving 0 files to the new cache system\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a35cfb1a0e6409a9bc4c4ab977d7da9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Preprocess"
      ],
      "metadata": {
        "id": "ASWOOmXqrvgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpyQQpirSyHj",
        "outputId": "d8e3db9a-49cb-47a3-cc77-ce8152229f28"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "Ui2HOCflrvgR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "# https://github.com/catSirup/KorEDA\n",
        "\n",
        "import random\n",
        "\n",
        "pos_aug_wordslist = [\"satisfying\", \"nice\", \"pretty good\", \"good\", \"excellent\", \"friendly\", \"apologetic\"]\n",
        "neg_aug_wordslist = [] # negative 단어를 찾지 못해서 일단 긍정적인 단어로만 성능 테스트\n",
        "\n",
        "def add_word(new_words, emotion_li):\n",
        "    if len(new_words) >= 1:\n",
        "        emotion_random_idx = random.randint(0, len(emotion_li)-1)\n",
        "        random_word = emotion_li[emotion_random_idx]\n",
        "        random_idx = random.randint(0, len(new_words)-1)\n",
        "        new_words.insert(random_idx, random_word)\n",
        "\n",
        "def random_insertion(words, n, emotion_li):\n",
        "    new_words = words.copy()\n",
        "    for _ in range(n):\n",
        "        add_word(new_words, emotion_li)\n",
        "    return new_words"
      ],
      "metadata": {
        "id": "H7aSBHn1BrBS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_cnt = 20000 # 증강할 문장 수 \n",
        "aug_n = 2 # 문장 당 증강할 단어 수\n",
        "\n",
        "def make_id_file(task, tokenizer):\n",
        "    def make_data_strings(file_name):\n",
        "        data_strings = []\n",
        "        with open(os.path.join('../content/drive/MyDrive/Goorm/project01/data', file_name), 'r', encoding='utf-8') as f:\n",
        "            id_file_data = [tokenizer.encode(line.lower()) for line in f.readlines()]\n",
        "        for item in id_file_data:\n",
        "            data_strings.append(' '.join([str(k) for k in item]))\n",
        "        return data_strings\n",
        "    \n",
        "    print('it will take some times...')\n",
        "    pos_before_aug = pd.read_csv('/content/drive/MyDrive/Goorm/project01/data/sentiment_train_1.csv')\n",
        "    \n",
        "    for i in range(aug_cnt):\n",
        "        words = pos_before_aug['Sentence'][i*5].split(' ')\n",
        "        insert_words = random_insertion(words, aug_n, pos_aug_wordslist)\n",
        "        inserted_sentence = \" \".join(insert_words)\n",
        "        pos_before_aug['Sentence'][i*5] = inserted_sentence\n",
        "\n",
        "    train_pos = pos_before_aug['Sentence'].to_list()\n",
        "\n",
        "    for i in range(len(pos_before_aug)):\n",
        "        train_pos[i] = ' '.join([str(k) for k in tokenizer.encode(train_pos[i])])\n",
        "    #train_pos = make_data_strings('sentiment.train.1')\n",
        "    train_neg = make_data_strings('sentiment.train.0')\n",
        "    dev_pos = make_data_strings('sentiment.dev.1')\n",
        "    dev_neg = make_data_strings('sentiment.dev.0')\n",
        "\n",
        "    print('make id file finished!')\n",
        "    return train_pos, train_neg, dev_pos, dev_neg"
      ],
      "metadata": {
        "id": "RAnU6w29rvgR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "ttzRlY4Ov0jZ",
        "outputId": "c88dfa1b-1c3a-424a-ed7c-aed042f1e144",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  pytorch_model.bin  sample_data  submission.csv  wandb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos, train_neg, dev_pos, dev_neg = make_id_file('yelp', tokenizer)"
      ],
      "metadata": {
        "id": "BAgztXIBrvgS",
        "outputId": "d6ea0372-7426-4ce9-92b8-8d0f9c21bea9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it will take some times...\n",
            "make id file finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos[:10]\n",
        "# train_neg[:10]"
      ],
      "metadata": {
        "id": "wRh2WjGRrvgS",
        "outputId": "cdf97841-a9a1-459c-9f86-41d342f13c3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['101 3492 2204 6581 29352 2833 1012 102',\n",
              " '101 21688 8013 2326 1012 102',\n",
              " '101 2027 2036 2031 3679 19247 1998 3256 6949 2029 2003 2428 2204 1012 102',\n",
              " '101 2009 1005 1055 1037 2204 15174 2098 7570 22974 2063 1012 102',\n",
              " '101 1996 3095 2003 5379 1012 102',\n",
              " '101 2204 3492 2204 3347 6581 2833 1012 102',\n",
              " '101 2204 2326 1012 102',\n",
              " '101 11350 1997 2154 2003 25628 1998 7167 1997 19247 1012 102',\n",
              " '101 2307 2173 2005 6265 2030 3347 27962 1998 5404 1012 102',\n",
              " '101 1996 2047 2846 3504 6429 1012 102']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentDataset(object):\n",
        "    def __init__(self, tokenizer, pos, neg):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "\n",
        "        for pos_sent in pos:\n",
        "            self.data += [self._cast_to_int(pos_sent.strip().split())]\n",
        "            self.label += [[1]]\n",
        "        for neg_sent in neg:\n",
        "            self.data += [self._cast_to_int(neg_sent.strip().split())]\n",
        "            self.label += [[0]]\n",
        "\n",
        "    def _cast_to_int(self, sample):\n",
        "        return [int(word_id) for word_id in sample]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        return np.array(sample), np.array(self.label[index])"
      ],
      "metadata": {
        "id": "JdpQQQMUrvgT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SentimentDataset(tokenizer, train_pos, train_neg)\n",
        "dev_dataset = SentimentDataset(tokenizer, dev_pos, dev_neg)"
      ],
      "metadata": {
        "id": "wCz5ey8xrvgU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, item in enumerate(train_dataset):\n",
        "    print(item)\n",
        "    if i == 10:\n",
        "        break"
      ],
      "metadata": {
        "id": "UuvkMczvrvgU",
        "outputId": "45d5df2c-45c8-4f28-a834-22826b4ab7e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([  101,  3492,  2204,  6581, 29352,  2833,  1012,   102]), array([1]))\n",
            "(array([  101, 21688,  8013,  2326,  1012,   102]), array([1]))\n",
            "(array([  101,  2027,  2036,  2031,  3679, 19247,  1998,  3256,  6949,\n",
            "        2029,  2003,  2428,  2204,  1012,   102]), array([1]))\n",
            "(array([  101,  2009,  1005,  1055,  1037,  2204, 15174,  2098,  7570,\n",
            "       22974,  2063,  1012,   102]), array([1]))\n",
            "(array([ 101, 1996, 3095, 2003, 5379, 1012,  102]), array([1]))\n",
            "(array([ 101, 2204, 3492, 2204, 3347, 6581, 2833, 1012,  102]), array([1]))\n",
            "(array([ 101, 2204, 2326, 1012,  102]), array([1]))\n",
            "(array([  101, 11350,  1997,  2154,  2003, 25628,  1998,  7167,  1997,\n",
            "       19247,  1012,   102]), array([1]))\n",
            "(array([  101,  2307,  2173,  2005,  6265,  2030,  3347, 27962,  1998,\n",
            "        5404,  1012,   102]), array([1]))\n",
            "(array([ 101, 1996, 2047, 2846, 3504, 6429, 1012,  102]), array([1]))\n",
            "(array([ 101, 2023, 2173, 5379, 2001, 2200, 5379, 2204, 1012,  102]), array([1]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn_style(samples):\n",
        "    # 나누어줌, 배치로 받으니까 복수s\n",
        "    input_ids, labels = zip(*samples)\n",
        "    # 배치 최대 길이\n",
        "    max_len = max(len(input_id) for input_id in input_ids)\n",
        "    # 길이 기준으로 정렬한 index return \n",
        "    sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1] \n",
        "    # sorted_indices = range(len(input_ids))\n",
        "\n",
        "    # 패딩 넣어줌, batch_first=True -> shape = B*max, batch_first=False -> shape = max*B(element-wise)\n",
        "    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n",
        "                             batch_first=True)\n",
        "    \n",
        "    # 길이 맞춰준 문장에서 의미 있는 토큰만 보기 위해 1, 0을 통해 살릴 부분 결정\n",
        "    attention_mask = torch.tensor(\n",
        "        [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n",
        "         sorted_indices])\n",
        "    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n",
        "    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n",
        "    labels = torch.tensor(np.stack(labels, axis=0)[sorted_indices])\n",
        "\n",
        "    return input_ids, attention_mask, token_type_ids, position_ids, labels"
      ],
      "metadata": {
        "id": "B0wRUBYSrvgU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collate_fn_style(train_dataset)"
      ],
      "metadata": {
        "id": "pa0EBGMgTeiq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "665596ef-d6bf-42a0-ee91-be827ad65a64"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 101, 1012, 1012,  ..., 1012, 1012,  102],\n",
              "         [ 101, 1996, 2326,  ...,    0,    0,    0],\n",
              "         [ 101, 1006, 1035,  ...,    0,    0,    0],\n",
              "         ...,\n",
              "         [ 101, 8699,  102,  ...,    0,    0,    0],\n",
              "         [ 101, 8699,  102,  ...,    0,    0,    0],\n",
              "         [ 101, 4997,  102,  ...,    0,    0,    0]]),\n",
              " tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         ...,\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [1, 1, 1,  ..., 1, 1, 1]]),\n",
              " tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
              " tensor([[ 0,  1,  2,  ..., 39, 40, 41],\n",
              "         [ 0,  1,  2,  ..., 39, 40, 41],\n",
              "         [ 0,  1,  2,  ..., 39, 40, 41],\n",
              "         ...,\n",
              "         [ 0,  1,  2,  ..., 39, 40, 41],\n",
              "         [ 0,  1,  2,  ..., 39, 40, 41],\n",
              "         [ 0,  1,  2,  ..., 39, 40, 41]]),\n",
              " tensor([[0],\n",
              "         [1],\n",
              "         [0],\n",
              "         ...,\n",
              "         [1],\n",
              "         [0],\n",
              "         [1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_batch_size=32\n",
        "eval_batch_size=32\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=train_batch_size,\n",
        "                                           shuffle=True, collate_fn=collate_fn_style,\n",
        "                                           pin_memory=True, num_workers=2)\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=eval_batch_size,\n",
        "                                         shuffle=False, collate_fn=collate_fn_style,\n",
        "                                         num_workers=2)"
      ],
      "metadata": {
        "id": "5saagig0rvgV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed\n",
        "random_seed=33\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "zvFqCaCnrvgW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa943dfe-e19f-4992-8ca2-60137d4a9df4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "learning_rate = 3e-5\n",
        "optimizer = AdamW(model.parameters(),lr= learning_rate)"
      ],
      "metadata": {
        "id": "0szZ2oUYy8eH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8286b07e-a42d-4758-aeaa-87f87c423471"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_acc(predictions, target_labels):\n",
        "    return (np.array(predictions) == np.array(target_labels)).mean()"
      ],
      "metadata": {
        "id": "MztU-L83rvgW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init()\n",
        "\n",
        "train_epoch = 3\n",
        "lowest_valid_loss = 9999.\n",
        "for epoch in range(train_epoch):\n",
        "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "        for iteration, (input_ids, attention_mask, token_type_ids, position_ids, labels) in enumerate(tepoch):\n",
        "            tepoch.set_description(f\"Epoch {epoch}\")\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            position_ids = position_ids.to(device)\n",
        "            labels = labels.to(device, dtype=torch.long)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(input_ids=input_ids,\n",
        "                           attention_mask=attention_mask,\n",
        "                           token_type_ids=token_type_ids,\n",
        "                           position_ids=position_ids,\n",
        "                           labels=labels)\n",
        "\n",
        "            loss = output.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "            if iteration != 0 and iteration % int(len(train_loader) / 5) == 0:\n",
        "                # Evaluate the model five times per epoch\n",
        "                with torch.no_grad():\n",
        "                    model.eval()\n",
        "                    valid_losses = []\n",
        "                    predictions = []\n",
        "                    target_labels = []\n",
        "                    for input_ids, attention_mask, token_type_ids, position_ids, labels in tqdm(dev_loader,\n",
        "                                                                                                desc='Eval',\n",
        "                                                                                                position=1,\n",
        "                                                                                                leave=None):\n",
        "                        input_ids = input_ids.to(device)\n",
        "                        attention_mask = attention_mask.to(device)\n",
        "                        token_type_ids = token_type_ids.to(device)\n",
        "                        position_ids = position_ids.to(device)\n",
        "                        labels = labels.to(device, dtype=torch.long)\n",
        "\n",
        "                        output = model(input_ids=input_ids,\n",
        "                                       attention_mask=attention_mask,\n",
        "                                       token_type_ids=token_type_ids,\n",
        "                                       position_ids=position_ids,\n",
        "                                       labels=labels)\n",
        "\n",
        "                        logits = output.logits\n",
        "                        loss = output.loss\n",
        "                        valid_losses.append(loss.item())\n",
        "\n",
        "                        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
        "                        batch_labels = [int(example) for example in labels]\n",
        "\n",
        "                        predictions += batch_predictions\n",
        "                        target_labels += batch_labels\n",
        "\n",
        "                acc = compute_acc(predictions, target_labels)\n",
        "                valid_loss = sum(valid_losses) / len(valid_losses)\n",
        "                wandb.log({\n",
        "                    \"Test Acc\": acc,\n",
        "                    \"Test Loss\": valid_loss,\n",
        "                    \"Learning Rate\": learning_rate})\n",
        "                if lowest_valid_loss > valid_loss:\n",
        "                    print('Acc for model which have lower valid loss: ', acc)\n",
        "                    torch.save(model.state_dict(), \"./pytorch_model.bin\")\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "DuZfvzpGrvgW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5afd03fd-78a1-4f4a-dae6-ae268c86c67d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221002_064610-30ixwwqp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ohseokjin/uncategorized/runs/30ixwwqp\" target=\"_blank\">light-grass-6</a></strong> to <a href=\"https://wandb.ai/ohseokjin/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  20%|█▉        | 2769/13852 [02:56<11:48, 15.64batch/s, loss=0.0143]\n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:16,  7.68it/s]\u001b[A\n",
            "Eval:   6%|▌         | 7/125 [00:00<00:03, 34.31it/s]\u001b[A\n",
            "Eval:  10%|█         | 13/125 [00:00<00:02, 44.51it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 19/125 [00:00<00:02, 49.56it/s]\u001b[A\n",
            "Eval:  20%|██        | 25/125 [00:00<00:01, 52.19it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 31/125 [00:00<00:01, 53.73it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 37/125 [00:00<00:01, 53.95it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 43/125 [00:00<00:01, 54.52it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 49/125 [00:00<00:01, 54.61it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 55/125 [00:01<00:01, 55.53it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 61/125 [00:01<00:01, 55.94it/s]\u001b[A\n",
            "Eval:  54%|█████▎    | 67/125 [00:01<00:01, 55.97it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 73/125 [00:01<00:00, 55.92it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 79/125 [00:01<00:00, 55.05it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 85/125 [00:01<00:00, 54.99it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 91/125 [00:01<00:00, 55.29it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 97/125 [00:01<00:00, 55.37it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 103/125 [00:01<00:00, 54.91it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 109/125 [00:02<00:00, 55.08it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 115/125 [00:02<00:00, 55.36it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 121/125 [00:02<00:00, 55.11it/s]\u001b[A\n",
            "                                                       \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  40%|███▉      | 5539/13852 [05:54<08:30, 16.27batch/s, loss=0.127] \n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:16,  7.64it/s]\u001b[A\n",
            "Eval:   6%|▌         | 7/125 [00:00<00:03, 32.22it/s]\u001b[A\n",
            "Eval:  10%|█         | 13/125 [00:00<00:02, 42.30it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 19/125 [00:00<00:02, 47.07it/s]\u001b[A\n",
            "Eval:  20%|██        | 25/125 [00:00<00:02, 49.79it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 31/125 [00:00<00:01, 51.15it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 37/125 [00:00<00:01, 52.96it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 43/125 [00:00<00:01, 53.64it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 49/125 [00:01<00:01, 53.01it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 55/125 [00:01<00:01, 53.90it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 61/125 [00:01<00:01, 53.53it/s]\u001b[A\n",
            "Eval:  54%|█████▎    | 67/125 [00:01<00:01, 53.71it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 73/125 [00:01<00:00, 52.72it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 79/125 [00:01<00:00, 51.85it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 85/125 [00:01<00:00, 52.62it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 91/125 [00:01<00:00, 52.35it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 97/125 [00:01<00:00, 52.71it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 103/125 [00:02<00:00, 53.30it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 109/125 [00:02<00:00, 52.99it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 115/125 [00:02<00:00, 53.18it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 121/125 [00:02<00:00, 53.40it/s]\u001b[A\n",
            "                                                       \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  60%|█████▉    | 8309/13852 [08:50<05:39, 16.32batch/s, loss=0.0693]\n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:16,  7.53it/s]\u001b[A\n",
            "Eval:   6%|▌         | 7/125 [00:00<00:03, 32.41it/s]\u001b[A\n",
            "Eval:  10%|█         | 13/125 [00:00<00:02, 42.48it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 19/125 [00:00<00:02, 46.83it/s]\u001b[A\n",
            "Eval:  20%|██        | 25/125 [00:00<00:02, 49.28it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 31/125 [00:00<00:01, 51.01it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 37/125 [00:00<00:01, 51.20it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 43/125 [00:00<00:01, 52.20it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 49/125 [00:01<00:01, 53.14it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 55/125 [00:01<00:01, 53.01it/s]\u001b[A\n",
            "Eval:  50%|████▉     | 62/125 [00:01<00:01, 55.42it/s]\u001b[A\n",
            "Eval:  54%|█████▍    | 68/125 [00:01<00:01, 55.79it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 74/125 [00:01<00:00, 55.61it/s]\u001b[A\n",
            "Eval:  64%|██████▍   | 80/125 [00:01<00:00, 55.25it/s]\u001b[A\n",
            "Eval:  69%|██████▉   | 86/125 [00:01<00:00, 55.05it/s]\u001b[A\n",
            "Eval:  74%|███████▎  | 92/125 [00:01<00:00, 54.47it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 98/125 [00:01<00:00, 54.64it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 104/125 [00:02<00:00, 54.77it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 110/125 [00:02<00:00, 54.56it/s]\u001b[A\n",
            "Eval:  93%|█████████▎| 116/125 [00:02<00:00, 54.60it/s]\u001b[A\n",
            "Eval:  98%|█████████▊| 122/125 [00:02<00:00, 55.19it/s]\u001b[A\n",
            "                                                       \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  80%|███████▉  | 11079/13852 [11:47<02:48, 16.48batch/s, loss=0.0732]\n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:16,  7.47it/s]\u001b[A\n",
            "Eval:   6%|▌         | 7/125 [00:00<00:03, 32.36it/s]\u001b[A\n",
            "Eval:  10%|█         | 13/125 [00:00<00:02, 41.95it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 19/125 [00:00<00:02, 46.90it/s]\u001b[A\n",
            "Eval:  20%|██        | 25/125 [00:00<00:02, 48.95it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 31/125 [00:00<00:01, 51.58it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 37/125 [00:00<00:01, 52.35it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 43/125 [00:00<00:01, 52.44it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 49/125 [00:01<00:01, 52.73it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 55/125 [00:01<00:01, 51.94it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 61/125 [00:01<00:01, 52.66it/s]\u001b[A\n",
            "Eval:  54%|█████▎    | 67/125 [00:01<00:01, 53.32it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 73/125 [00:01<00:00, 52.84it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 79/125 [00:01<00:00, 52.65it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 85/125 [00:01<00:00, 53.44it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 91/125 [00:01<00:00, 53.56it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 97/125 [00:01<00:00, 54.39it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 103/125 [00:02<00:00, 53.87it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 109/125 [00:02<00:00, 53.66it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 115/125 [00:02<00:00, 53.93it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 121/125 [00:02<00:00, 54.36it/s]\u001b[A\n",
            "                                                       \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|█████████▉| 13849/13852 [14:44<00:00, 14.91batch/s, loss=0.0137]\n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:16,  7.55it/s]\u001b[A\n",
            "Eval:   6%|▌         | 7/125 [00:00<00:03, 32.58it/s]\u001b[A\n",
            "Eval:  10%|█         | 13/125 [00:00<00:02, 41.41it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 19/125 [00:00<00:02, 46.40it/s]\u001b[A\n",
            "Eval:  20%|██        | 25/125 [00:00<00:02, 49.85it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 31/125 [00:00<00:01, 52.50it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 37/125 [00:00<00:01, 53.12it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 43/125 [00:00<00:01, 53.66it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 49/125 [00:01<00:01, 54.19it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 55/125 [00:01<00:01, 54.92it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 61/125 [00:01<00:01, 55.50it/s]\u001b[A\n",
            "Eval:  54%|█████▎    | 67/125 [00:01<00:01, 55.30it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 73/125 [00:01<00:00, 54.40it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 79/125 [00:01<00:00, 54.02it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 85/125 [00:01<00:00, 53.98it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 91/125 [00:01<00:00, 54.60it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 97/125 [00:01<00:00, 54.74it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 103/125 [00:01<00:00, 54.77it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 109/125 [00:02<00:00, 55.05it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 115/125 [00:02<00:00, 54.26it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 121/125 [00:02<00:00, 54.99it/s]\u001b[A\n",
            "                                                       \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 13852/13852 [14:48<00:00, 15.59batch/s, loss=0.157]\n",
            "Epoch 1:  20%|█▉        | 2769/13852 [02:55<11:55, 15.48batch/s, loss=0.0186]\n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:16,  7.61it/s]\u001b[A\n",
            "Eval:   6%|▌         | 7/125 [00:00<00:03, 33.06it/s]\u001b[A\n",
            "Eval:  10%|█         | 13/125 [00:00<00:02, 41.85it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 19/125 [00:00<00:02, 46.30it/s]\u001b[A\n",
            "Eval:  20%|██        | 25/125 [00:00<00:02, 49.04it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 31/125 [00:00<00:01, 51.58it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 37/125 [00:00<00:01, 52.10it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 43/125 [00:00<00:01, 52.31it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 49/125 [00:01<00:01, 52.60it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 55/125 [00:01<00:01, 53.29it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 61/125 [00:01<00:01, 54.12it/s]\u001b[A\n",
            "Eval:  54%|█████▎    | 67/125 [00:01<00:01, 53.87it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 73/125 [00:01<00:00, 54.32it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 79/125 [00:01<00:00, 54.17it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 85/125 [00:01<00:00, 54.97it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 91/125 [00:01<00:00, 55.01it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 97/125 [00:01<00:00, 54.89it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 103/125 [00:02<00:00, 55.12it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 109/125 [00:02<00:00, 55.31it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 115/125 [00:02<00:00, 54.98it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 121/125 [00:02<00:00, 55.27it/s]\u001b[A\n",
            "                                                       \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  40%|███▉      | 5539/13852 [05:52<08:31, 16.25batch/s, loss=0.101] \n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:16,  7.73it/s]\u001b[A\n",
            "Eval:   6%|▌         | 7/125 [00:00<00:03, 32.47it/s]\u001b[A\n",
            "Eval:  10%|█         | 13/125 [00:00<00:02, 42.29it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 19/125 [00:00<00:02, 47.43it/s]\u001b[A\n",
            "Eval:  20%|██        | 25/125 [00:00<00:01, 50.65it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 31/125 [00:00<00:01, 52.35it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 37/125 [00:00<00:01, 53.73it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 43/125 [00:00<00:01, 55.10it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 49/125 [00:00<00:01, 54.27it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 55/125 [00:01<00:01, 53.56it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 61/125 [00:01<00:01, 54.39it/s]\u001b[A\n",
            "Eval:  54%|█████▎    | 67/125 [00:01<00:01, 54.01it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 73/125 [00:01<00:00, 54.58it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 79/125 [00:01<00:00, 55.11it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 85/125 [00:01<00:00, 55.51it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 91/125 [00:01<00:00, 55.65it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 97/125 [00:01<00:00, 55.11it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 103/125 [00:01<00:00, 54.21it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 109/125 [00:02<00:00, 54.65it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 115/125 [00:02<00:00, 53.92it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 121/125 [00:02<00:00, 54.34it/s]\u001b[A\n",
            "                                                       \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  60%|█████▉    | 8309/13852 [08:47<05:43, 16.12batch/s, loss=0.00345]\n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:15,  7.88it/s]\u001b[A\n",
            "Eval:   6%|▌         | 7/125 [00:00<00:03, 32.69it/s]\u001b[A\n",
            "Eval:  10%|█         | 13/125 [00:00<00:02, 43.00it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 19/125 [00:00<00:02, 47.62it/s]\u001b[A\n",
            "Eval:  20%|██        | 25/125 [00:00<00:01, 50.11it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 31/125 [00:00<00:01, 51.74it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 37/125 [00:00<00:01, 52.65it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 43/125 [00:00<00:01, 53.19it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 49/125 [00:01<00:01, 54.71it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 55/125 [00:01<00:01, 54.75it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 61/125 [00:01<00:01, 54.80it/s]\u001b[A\n",
            "Eval:  54%|█████▎    | 67/125 [00:01<00:01, 54.52it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 73/125 [00:01<00:00, 53.52it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 79/125 [00:01<00:00, 54.19it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 85/125 [00:01<00:00, 54.37it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 91/125 [00:01<00:00, 54.93it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 97/125 [00:01<00:00, 55.05it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 103/125 [00:01<00:00, 55.00it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 109/125 [00:02<00:00, 54.91it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 115/125 [00:02<00:00, 55.35it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 121/125 [00:02<00:00, 55.16it/s]\u001b[A\n",
            "                                                       \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  80%|███████▉  | 11079/13852 [11:44<02:52, 16.11batch/s, loss=0.0264] \n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:16,  7.66it/s]\u001b[A\n",
            "Eval:   5%|▍         | 6/125 [00:00<00:04, 29.45it/s]\u001b[A\n",
            "Eval:  10%|▉         | 12/125 [00:00<00:02, 41.06it/s]\u001b[A\n",
            "Eval:  14%|█▍        | 18/125 [00:00<00:02, 46.68it/s]\u001b[A\n",
            "Eval:  19%|█▉        | 24/125 [00:00<00:02, 49.22it/s]\u001b[A\n",
            "Eval:  24%|██▍       | 30/125 [00:00<00:01, 52.04it/s]\u001b[A\n",
            "Eval:  29%|██▉       | 36/125 [00:00<00:01, 52.84it/s]\u001b[A\n",
            "Eval:  34%|███▎      | 42/125 [00:00<00:01, 53.53it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 48/125 [00:00<00:01, 53.83it/s]\u001b[A\n",
            "Eval:  43%|████▎     | 54/125 [00:01<00:01, 54.28it/s]\u001b[A\n",
            "Eval:  48%|████▊     | 60/125 [00:01<00:01, 54.87it/s]\u001b[A\n",
            "Eval:  53%|█████▎    | 66/125 [00:01<00:01, 56.02it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 72/125 [00:01<00:00, 55.91it/s]\u001b[A\n",
            "Eval:  62%|██████▏   | 78/125 [00:01<00:00, 55.60it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 84/125 [00:01<00:00, 55.71it/s]\u001b[A\n",
            "Eval:  72%|███████▏  | 90/125 [00:01<00:00, 55.80it/s]\u001b[A\n",
            "Eval:  77%|███████▋  | 96/125 [00:01<00:00, 55.39it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 102/125 [00:01<00:00, 55.44it/s]\u001b[A\n",
            "Eval:  86%|████████▋ | 108/125 [00:02<00:00, 55.06it/s]\u001b[A\n",
            "Eval:  91%|█████████ | 114/125 [00:02<00:00, 54.69it/s]\u001b[A\n",
            "Eval:  96%|█████████▌| 120/125 [00:02<00:00, 54.55it/s]\u001b[A\n",
            "                                                       \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|█████████▉| 13849/13852 [14:40<00:00, 15.28batch/s, loss=0.0429]\n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:16,  7.61it/s]\u001b[A\n",
            "Eval:   6%|▌         | 7/125 [00:00<00:03, 33.39it/s]\u001b[A\n",
            "Eval:  10%|█         | 13/125 [00:00<00:02, 42.80it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 19/125 [00:00<00:02, 47.18it/s]\u001b[A\n",
            "Eval:  20%|██        | 25/125 [00:00<00:02, 49.39it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 31/125 [00:00<00:01, 51.17it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 37/125 [00:00<00:01, 52.23it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 43/125 [00:00<00:01, 53.22it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 49/125 [00:01<00:01, 53.20it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 55/125 [00:01<00:01, 53.85it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 61/125 [00:01<00:01, 54.18it/s]\u001b[A\n",
            "Eval:  54%|█████▎    | 67/125 [00:01<00:01, 53.46it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 73/125 [00:01<00:00, 53.38it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 79/125 [00:01<00:00, 53.38it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 85/125 [00:01<00:00, 53.89it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 91/125 [00:01<00:00, 53.83it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 97/125 [00:01<00:00, 54.00it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 103/125 [00:02<00:00, 54.09it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 109/125 [00:02<00:00, 54.63it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 115/125 [00:02<00:00, 53.99it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 121/125 [00:02<00:00, 53.66it/s]\u001b[A\n",
            "                                                       \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 13852/13852 [14:44<00:00, 15.66batch/s, loss=0.0815]\n",
            "Epoch 2:  20%|█▉        | 2769/13852 [02:53<11:22, 16.23batch/s, loss=0.00762]\n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:16,  7.53it/s]\u001b[A\n",
            "Eval:   6%|▌         | 7/125 [00:00<00:03, 32.49it/s]\u001b[A\n",
            "Eval:  10%|█         | 13/125 [00:00<00:02, 42.22it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 19/125 [00:00<00:02, 46.12it/s]\u001b[A\n",
            "Eval:  20%|██        | 25/125 [00:00<00:01, 50.12it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 31/125 [00:00<00:01, 51.54it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 37/125 [00:00<00:01, 52.43it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 43/125 [00:00<00:01, 53.86it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 49/125 [00:01<00:01, 54.84it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 55/125 [00:01<00:01, 55.41it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 61/125 [00:01<00:01, 55.23it/s]\u001b[A\n",
            "Eval:  54%|█████▎    | 67/125 [00:01<00:01, 54.90it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 73/125 [00:01<00:00, 54.71it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 79/125 [00:01<00:00, 54.94it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 85/125 [00:01<00:00, 54.88it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 91/125 [00:01<00:00, 55.13it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 97/125 [00:01<00:00, 54.91it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 103/125 [00:01<00:00, 54.92it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 109/125 [00:02<00:00, 55.23it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 115/125 [00:02<00:00, 54.31it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 121/125 [00:02<00:00, 53.63it/s]\u001b[A\n",
            "                                                       \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.9765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  40%|███▉      | 5539/13852 [05:48<08:44, 15.84batch/s, loss=0.00331]\n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:16,  7.46it/s]\u001b[A\n",
            "Eval:   6%|▌         | 7/125 [00:00<00:03, 32.14it/s]\u001b[A\n",
            "Eval:  10%|█         | 13/125 [00:00<00:02, 41.89it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 19/125 [00:00<00:02, 46.50it/s]\u001b[A\n",
            "Eval:  20%|██        | 25/125 [00:00<00:01, 50.00it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 31/125 [00:00<00:01, 53.01it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 37/125 [00:00<00:01, 52.60it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 43/125 [00:00<00:01, 53.54it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 49/125 [00:01<00:01, 54.22it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 55/125 [00:01<00:01, 54.74it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 61/125 [00:01<00:01, 55.17it/s]\u001b[A\n",
            "Eval:  54%|█████▎    | 67/125 [00:01<00:01, 54.68it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 73/125 [00:01<00:00, 53.62it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 79/125 [00:01<00:00, 53.77it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 85/125 [00:01<00:00, 55.00it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 91/125 [00:01<00:00, 54.90it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 97/125 [00:01<00:00, 54.40it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 103/125 [00:01<00:00, 54.56it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 109/125 [00:02<00:00, 54.85it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 115/125 [00:02<00:00, 54.41it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 121/125 [00:02<00:00, 54.29it/s]\u001b[A\n",
            "                                                       \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  60%|█████▉    | 8309/13852 [08:46<05:53, 15.67batch/s, loss=0.00153] \n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:16,  7.66it/s]\u001b[A\n",
            "Eval:   6%|▌         | 7/125 [00:00<00:03, 32.49it/s]\u001b[A\n",
            "Eval:  10%|█         | 13/125 [00:00<00:02, 41.71it/s]\u001b[A\n",
            "Eval:  15%|█▌        | 19/125 [00:00<00:02, 45.16it/s]\u001b[A\n",
            "Eval:  20%|██        | 25/125 [00:00<00:02, 48.59it/s]\u001b[A\n",
            "Eval:  25%|██▍       | 31/125 [00:00<00:01, 50.72it/s]\u001b[A\n",
            "Eval:  30%|██▉       | 37/125 [00:00<00:01, 51.72it/s]\u001b[A\n",
            "Eval:  34%|███▍      | 43/125 [00:00<00:01, 52.38it/s]\u001b[A\n",
            "Eval:  39%|███▉      | 49/125 [00:01<00:01, 52.56it/s]\u001b[A\n",
            "Eval:  44%|████▍     | 55/125 [00:01<00:01, 52.91it/s]\u001b[A\n",
            "Eval:  49%|████▉     | 61/125 [00:01<00:01, 51.00it/s]\u001b[A\n",
            "Eval:  54%|█████▎    | 67/125 [00:01<00:01, 50.79it/s]\u001b[A\n",
            "Eval:  58%|█████▊    | 73/125 [00:01<00:01, 51.37it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 79/125 [00:01<00:00, 51.80it/s]\u001b[A\n",
            "Eval:  68%|██████▊   | 85/125 [00:01<00:00, 51.77it/s]\u001b[A\n",
            "Eval:  73%|███████▎  | 91/125 [00:01<00:00, 52.56it/s]\u001b[A\n",
            "Eval:  78%|███████▊  | 97/125 [00:01<00:00, 53.58it/s]\u001b[A\n",
            "Eval:  82%|████████▏ | 103/125 [00:02<00:00, 53.45it/s]\u001b[A\n",
            "Eval:  87%|████████▋ | 109/125 [00:02<00:00, 52.56it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 115/125 [00:02<00:00, 52.31it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 121/125 [00:02<00:00, 52.27it/s]\u001b[A\n",
            "                                                       \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.97925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  80%|███████▉  | 11079/13852 [11:44<03:11, 14.50batch/s, loss=0.00156]\n",
            "Eval:   0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:   1%|          | 1/125 [00:00<00:16,  7.62it/s]\u001b[A\n",
            "Eval:   5%|▍         | 6/125 [00:00<00:04, 29.54it/s]\u001b[A\n",
            "Eval:   9%|▉         | 11/125 [00:00<00:03, 37.83it/s]\u001b[A\n",
            "Eval:  14%|█▎        | 17/125 [00:00<00:02, 44.43it/s]\u001b[A\n",
            "Eval:  18%|█▊        | 22/125 [00:00<00:02, 45.61it/s]\u001b[A\n",
            "Eval:  22%|██▏       | 28/125 [00:00<00:02, 47.70it/s]\u001b[A\n",
            "Eval:  27%|██▋       | 34/125 [00:00<00:01, 50.61it/s]\u001b[A\n",
            "Eval:  32%|███▏      | 40/125 [00:00<00:01, 51.06it/s]\u001b[A\n",
            "Eval:  37%|███▋      | 46/125 [00:01<00:01, 51.47it/s]\u001b[A\n",
            "Eval:  42%|████▏     | 52/125 [00:01<00:01, 52.62it/s]\u001b[A\n",
            "Eval:  46%|████▋     | 58/125 [00:01<00:01, 52.01it/s]\u001b[A\n",
            "Eval:  51%|█████     | 64/125 [00:01<00:01, 49.37it/s]\u001b[A\n",
            "Eval:  55%|█████▌    | 69/125 [00:01<00:01, 47.82it/s]\u001b[A\n",
            "Eval:  59%|█████▉    | 74/125 [00:01<00:01, 44.65it/s]\u001b[A\n",
            "Eval:  63%|██████▎   | 79/125 [00:01<00:01, 42.63it/s]\u001b[A\n",
            "Eval:  67%|██████▋   | 84/125 [00:01<00:00, 43.38it/s]\u001b[A\n",
            "Eval:  71%|███████   | 89/125 [00:01<00:00, 43.01it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 94/125 [00:02<00:00, 43.33it/s]\u001b[A\n",
            "Eval:  79%|███████▉  | 99/125 [00:02<00:00, 44.84it/s]\u001b[A\n",
            "Eval:  83%|████████▎ | 104/125 [00:02<00:00, 45.73it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 110/125 [00:02<00:00, 48.10it/s]\u001b[A\n",
            "Eval:  92%|█████████▏| 115/125 [00:02<00:00, 48.14it/s]\u001b[A\n",
            "Eval:  97%|█████████▋| 121/125 [00:02<00:00, 49.53it/s]\u001b[A\n",
            "                                                       \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.98025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  82%|████████▏ | 11333/13852 [12:04<02:35, 16.19batch/s, loss=0.0112]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_df = pd.read_csv('../content/drive/MyDrive/Goorm/project01/data/test_no_label.csv')"
      ],
      "metadata": {
        "id": "P95gtlnurvgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = test_df['Id']"
      ],
      "metadata": {
        "id": "cLDzC10ErvgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_id_file_test(tokenizer, test_dataset):\n",
        "    data_strings = []\n",
        "    id_file_data = [tokenizer.encode(sent.lower()) for sent in test_dataset]\n",
        "    for item in id_file_data:\n",
        "        data_strings.append(' '.join([str(k) for k in item]))\n",
        "    return data_strings"
      ],
      "metadata": {
        "id": "jnt693N0rvgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = make_id_file_test(tokenizer, test_dataset)"
      ],
      "metadata": {
        "id": "7C5PpXtlrvgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentTestDataset(object):\n",
        "    def __init__(self, tokenizer, test):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "\n",
        "        for sent in test:\n",
        "            self.data += [self._cast_to_int(sent.strip().split())]\n",
        "\n",
        "    def _cast_to_int(self, sample):\n",
        "        return [int(word_id) for word_id in sample]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        return np.array(sample)"
      ],
      "metadata": {
        "id": "cZi14gnnrvgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = SentimentTestDataset(tokenizer, test)"
      ],
      "metadata": {
        "id": "erHjGE9rrvgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn_style_test(samples):\n",
        "    input_ids = samples\n",
        "    max_len = max(len(input_id) for input_id in input_ids)\n",
        "    # sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1]\n",
        "    sorted_indices = range(len(input_ids))\n",
        "\n",
        "    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n",
        "                             batch_first=True)\n",
        "    attention_mask = torch.tensor(\n",
        "        [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n",
        "         sorted_indices])\n",
        "    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n",
        "    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n",
        "\n",
        "    return input_ids, attention_mask, token_type_ids, position_ids"
      ],
      "metadata": {
        "id": "y03-nDX9rvgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_batch_size = 128\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size,\n",
        "                                          shuffle=False, collate_fn=collate_fn_style_test,\n",
        "                                          num_workers=2)"
      ],
      "metadata": {
        "id": "gZ0l1HparvgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    for input_ids, attention_mask, token_type_ids, position_ids in tqdm(test_loader,\n",
        "                                                                        desc='Test',\n",
        "                                                                        position=1,\n",
        "                                                                        leave=None):\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "        position_ids = position_ids.to(device)\n",
        "\n",
        "        output = model(input_ids=input_ids,\n",
        "                       attention_mask=attention_mask,\n",
        "                       token_type_ids=token_type_ids,\n",
        "                       position_ids=position_ids)\n",
        "\n",
        "        logits = output.logits\n",
        "        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
        "        predictions += batch_predictions"
      ],
      "metadata": {
        "id": "XoSHTbJUrvgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['Category'] = predictions"
      ],
      "metadata": {
        "id": "tGO3aS-VrvgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "VndXxal3rvgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test before submission"
      ],
      "metadata": {
        "id": "-jb2PFrsYH3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# best acc = 0.988\n",
        "Best_submission = pd.read_csv('../content/drive/MyDrive/Goorm/project01/data/Best_submission.csv')\n",
        "My_submission = pd.read_csv('/content/submission.csv')"
      ],
      "metadata": {
        "id": "teI5bcj7YNbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_list = []\n",
        "cnt = 0\n",
        "\n",
        "for i in range(1000):\n",
        "    if Best_submission['Category'][i] != My_submission['Category'][i]:\n",
        "        check_list.append(i+2)\n",
        "        cnt += 1\n",
        "\n",
        "print(check_list)\n",
        "print(cnt)"
      ],
      "metadata": {
        "id": "_hYMNyIPYnH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble"
      ],
      "metadata": {
        "id": "NDWmfXVJUOfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Submission1 = pd.read_csv('/content/drive/MyDrive/Goorm/project01/data/submission_using albert model & fix attention mask.csv')\n",
        "Submission2 = pd.read_csv('/content/drive/MyDrive/Goorm/project01/data/submission_latestbydoongle.csv')\n",
        "Submission3 = pd.read_csv('/content/drive/MyDrive/Goorm/project01/data/submission_withaugmentation.csv')\n",
        "Submission4 = pd.read_csv('/content/drive/MyDrive/Goorm/project01/data/submission_electra_lrweight_decay.csv')\n",
        "Submission5 = pd.read_csv('/content/drive/MyDrive/Goorm/project01/data/submission_BERT_base.csv')\n",
        "\n",
        "test_df = pd.read_csv('../content/drive/MyDrive/Goorm/project01/data/test_no_label.csv')"
      ],
      "metadata": {
        "id": "YqCABkqGUSma"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_predictions = []\n",
        "\n",
        "for i in range(1000):\n",
        "    ensemble_prediction = math.floor((Submission1['Category'][i] +\n",
        "                                      Submission2['Category'][i] +\n",
        "                                      Submission3['Category'][i] + \n",
        "                                      Submission4['Category'][i] + \n",
        "                                      Submission5['Category'][i])/5)\n",
        "    ensemble_predictions.append(ensemble_prediction)"
      ],
      "metadata": {
        "id": "s636xoTtU_tI"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['Category'] = ensemble_predictions"
      ],
      "metadata": {
        "id": "CxLyB71vVLJo"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "id": "s240_wVfSGeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "ZazTyylUVKeY"
      },
      "execution_count": 49,
      "outputs": []
    }
  ]
}