{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oh-Seokjin/MRC_goorm/blob/main/kobigbird_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9_b4TH6FKAm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "a92cc31b-a5e0-4768-8619-803b5388f0c3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ca2fe4c1-a7fa-4e67-b2d3-56a78cede5b4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ca2fe4c1-a7fa-4e67-b2d3-56a78cede5b4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving klue-mrc-v1.1_dev.json to klue-mrc-v1.1_dev.json\n",
            "Saving test.json to test.json\n",
            "Saving train.json to train.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uof0ti2IEVCN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af04dc82-93b3-4e10-a816-b1573a5ea87d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "python3-dev set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n",
            "  openjdk-8-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  gvfs openjdk-8-demo openjdk-8-source visualvm libnss-mdns\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless\n",
            "  openjdk-8-jre openjdk-8-jre-headless x11-utils\n",
            "0 upgraded, 15 newly installed, 0 to remove and 22 not upgraded.\n",
            "Need to get 46.0 MB of archives.\n",
            "After this operation, 166 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u342-b07-0ubuntu1~18.04 [28.3 MB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u342-b07-0ubuntu1~18.04 [69.6 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u342-b07-0ubuntu1~18.04 [8,300 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u342-b07-0ubuntu1~18.04 [4,032 kB]\n",
            "Fetched 46.0 MB in 1s (42.4 MB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 123941 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../01-fonts-dejavu-core_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../02-fonts-dejavu-extra_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../03-x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../04-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../05-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../06-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../07-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../08-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../09-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../10-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../11-openjdk-8-jre-headless_8u342-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../12-openjdk-8-jre_8u342-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../13-openjdk-8-jdk-headless_8u342-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
            "Preparing to unpack .../14-openjdk-8-jdk_8u342-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Setting up fonts-dejavu-core (2.37-1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Setting up openjdk-8-jre:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Setting up openjdk-8-jdk:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy<4.0.0 in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy<4.0.0) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy<4.0.0) (1.3.1)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy<4.0.0) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy<4.0.0) (3.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy<4.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy<4.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy<4.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy<4.0.0) (2022.9.24)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy<4.0.0) (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 81.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n",
            "Installing automake (A dependency for mecab-ko)\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [95.2 kB]\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [983 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,467 kB]\n",
            "Hit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,332 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,248 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,035 kB]\n",
            "Hit:18 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,208 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,554 kB]\n",
            "Hit:21 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,165 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,109 kB]\n",
            "Fetched 17.5 MB in 3s (5,921 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  autoconf autotools-dev libsigsegv2 m4\n",
            "Suggested packages:\n",
            "  autoconf-archive gnu-standards autoconf-doc libtool gettext m4-doc\n",
            "The following NEW packages will be installed:\n",
            "  autoconf automake autotools-dev libsigsegv2 m4\n",
            "0 upgraded, 5 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 1,082 kB of archives.\n",
            "After this operation, 3,994 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 autoconf all 2.69-11 [322 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 automake all 1:1.15.1-3ubuntu2 [509 kB]\n",
            "Fetched 1,082 kB in 0s (2,843 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 5.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libsigsegv2:amd64.\n",
            "(Reading database ... 124520 files and directories currently installed.)\n",
            "Preparing to unpack .../libsigsegv2_2.12-1_amd64.deb ...\n",
            "Unpacking libsigsegv2:amd64 (2.12-1) ...\n",
            "Selecting previously unselected package m4.\n",
            "Preparing to unpack .../archives/m4_1.4.18-1_amd64.deb ...\n",
            "Unpacking m4 (1.4.18-1) ...\n",
            "Selecting previously unselected package autoconf.\n",
            "Preparing to unpack .../autoconf_2.69-11_all.deb ...\n",
            "Unpacking autoconf (2.69-11) ...\n",
            "Selecting previously unselected package autotools-dev.\n",
            "Preparing to unpack .../autotools-dev_20180224.1_all.deb ...\n",
            "Unpacking autotools-dev (20180224.1) ...\n",
            "Selecting previously unselected package automake.\n",
            "Preparing to unpack .../automake_1%3a1.15.1-3ubuntu2_all.deb ...\n",
            "Unpacking automake (1:1.15.1-3ubuntu2) ...\n",
            "Setting up libsigsegv2:amd64 (2.12-1) ...\n",
            "Setting up m4 (1.4.18-1) ...\n",
            "Setting up autotools-dev (20180224.1) ...\n",
            "Setting up autoconf (2.69-11) ...\n",
            "Setting up automake (1:1.15.1-3ubuntu2) ...\n",
            "update-alternatives: using /usr/bin/automake-1.15 to provide /usr/bin/automake (automake) in auto mode\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Install mecab-ko\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1381k  100 1381k    0     0  1442k      0 --:--:-- --:--:-- --:--:-- 1442k\n",
            "mecab-0.996-ko-0.9.2/\n",
            "mecab-0.996-ko-0.9.2/example/\n",
            "mecab-0.996-ko-0.9.2/example/example.cpp\n",
            "mecab-0.996-ko-0.9.2/example/example_lattice.cpp\n",
            "mecab-0.996-ko-0.9.2/example/example_lattice.c\n",
            "mecab-0.996-ko-0.9.2/example/example.c\n",
            "mecab-0.996-ko-0.9.2/example/thread_test.cpp\n",
            "mecab-0.996-ko-0.9.2/mecab-config.in\n",
            "mecab-0.996-ko-0.9.2/man/\n",
            "mecab-0.996-ko-0.9.2/man/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/man/mecab.1\n",
            "mecab-0.996-ko-0.9.2/man/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/mecab.iss.in\n",
            "mecab-0.996-ko-0.9.2/config.guess\n",
            "mecab-0.996-ko-0.9.2/README\n",
            "mecab-0.996-ko-0.9.2/COPYING\n",
            "mecab-0.996-ko-0.9.2/CHANGES.md\n",
            "mecab-0.996-ko-0.9.2/README.md\n",
            "mecab-0.996-ko-0.9.2/INSTALL\n",
            "mecab-0.996-ko-0.9.2/config.sub\n",
            "mecab-0.996-ko-0.9.2/configure.in\n",
            "mecab-0.996-ko-0.9.2/swig/\n",
            "mecab-0.996-ko-0.9.2/swig/Makefile\n",
            "mecab-0.996-ko-0.9.2/swig/version.h.in\n",
            "mecab-0.996-ko-0.9.2/swig/version.h\n",
            "mecab-0.996-ko-0.9.2/swig/MeCab.i\n",
            "mecab-0.996-ko-0.9.2/aclocal.m4\n",
            "mecab-0.996-ko-0.9.2/LGPL\n",
            "mecab-0.996-ko-0.9.2/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/configure\n",
            "mecab-0.996-ko-0.9.2/tests/\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/test\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/t9/\n",
            "mecab-0.996-ko-0.9.2/tests/t9/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/ipadic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/t9/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/t9/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/t9/test\n",
            "mecab-0.996-ko-0.9.2/tests/t9/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/mkdic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/t9/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.train\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.test\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/rewrite.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/feature.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/run-eval.sh\n",
            "mecab-0.996-ko-0.9.2/tests/run-cost-train.sh\n",
            "mecab-0.996-ko-0.9.2/tests/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/test\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/eval/\n",
            "mecab-0.996-ko-0.9.2/tests/eval/answer\n",
            "mecab-0.996-ko-0.9.2/tests/eval/system\n",
            "mecab-0.996-ko-0.9.2/tests/eval/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/test\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/mkdic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/latin/\n",
            "mecab-0.996-ko-0.9.2/tests/latin/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/latin/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/latin/test\n",
            "mecab-0.996-ko-0.9.2/tests/latin/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/test\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/run-dics.sh\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/test\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/ltmain.sh\n",
            "mecab-0.996-ko-0.9.2/config.rpath\n",
            "mecab-0.996-ko-0.9.2/config.h.in\n",
            "mecab-0.996-ko-0.9.2/mecabrc.in\n",
            "mecab-0.996-ko-0.9.2/GPL\n",
            "mecab-0.996-ko-0.9.2/Makefile.train\n",
            "mecab-0.996-ko-0.9.2/ChangeLog\n",
            "mecab-0.996-ko-0.9.2/install-sh\n",
            "mecab-0.996-ko-0.9.2/AUTHORS\n",
            "mecab-0.996-ko-0.9.2/doc/\n",
            "mecab-0.996-ko-0.9.2/doc/bindings.html\n",
            "mecab-0.996-ko-0.9.2/doc/posid.html\n",
            "mecab-0.996-ko-0.9.2/doc/unk.html\n",
            "mecab-0.996-ko-0.9.2/doc/learn.html\n",
            "mecab-0.996-ko-0.9.2/doc/format.html\n",
            "mecab-0.996-ko-0.9.2/doc/libmecab.html\n",
            "mecab-0.996-ko-0.9.2/doc/mecab.css\n",
            "mecab-0.996-ko-0.9.2/doc/feature.html\n",
            "mecab-0.996-ko-0.9.2/doc/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/doc/soft.html\n",
            "mecab-0.996-ko-0.9.2/doc/en/\n",
            "mecab-0.996-ko-0.9.2/doc/en/bindings.html\n",
            "mecab-0.996-ko-0.9.2/doc/dic-detail.html\n",
            "mecab-0.996-ko-0.9.2/doc/flow.png\n",
            "mecab-0.996-ko-0.9.2/doc/mecab.html\n",
            "mecab-0.996-ko-0.9.2/doc/index.html\n",
            "mecab-0.996-ko-0.9.2/doc/result.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_a.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_eval.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions_vars.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.css\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_r.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h_source.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tabs.css\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/nav_f.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/nav_h.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_h.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/closed.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_l.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_type.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_s.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_type.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespaces.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespaceMeCab.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/files.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/index.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/annotated.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_defs.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classes.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h-source.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/bc_s.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/open.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h.html\n",
            "mecab-0.996-ko-0.9.2/doc/dic.html\n",
            "mecab-0.996-ko-0.9.2/doc/partial.html\n",
            "mecab-0.996-ko-0.9.2/doc/feature.png\n",
            "mecab-0.996-ko-0.9.2/doc/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/missing\n",
            "mecab-0.996-ko-0.9.2/BSD\n",
            "mecab-0.996-ko-0.9.2/NEWS\n",
            "mecab-0.996-ko-0.9.2/mkinstalldirs\n",
            "mecab-0.996-ko-0.9.2/src/\n",
            "mecab-0.996-ko-0.9.2/src/dictionary.h\n",
            "mecab-0.996-ko-0.9.2/src/writer.h\n",
            "mecab-0.996-ko-0.9.2/src/utils.h\n",
            "mecab-0.996-ko-0.9.2/src/string_buffer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tokenizer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/make.bat\n",
            "mecab-0.996-ko-0.9.2/src/mecab.h\n",
            "mecab-0.996-ko-0.9.2/src/freelist.h\n",
            "mecab-0.996-ko-0.9.2/src/string_buffer.h\n",
            "mecab-0.996-ko-0.9.2/src/learner_tagger.h\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_compiler.cpp\n",
            "mecab-0.996-ko-0.9.2/src/eval.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-system-eval.cpp\n",
            "mecab-0.996-ko-0.9.2/src/darts.h\n",
            "mecab-0.996-ko-0.9.2/src/param.h\n",
            "mecab-0.996-ko-0.9.2/src/char_property.h\n",
            "mecab-0.996-ko-0.9.2/src/learner_node.h\n",
            "mecab-0.996-ko-0.9.2/src/mecab-dict-gen.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-dict-index.cpp\n",
            "mecab-0.996-ko-0.9.2/src/winmain.h\n",
            "mecab-0.996-ko-0.9.2/src/thread.h\n",
            "mecab-0.996-ko-0.9.2/src/context_id.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/src/connector.h\n",
            "mecab-0.996-ko-0.9.2/src/common.h\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.msvc.in\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.h\n",
            "mecab-0.996-ko-0.9.2/src/feature_index.h\n",
            "mecab-0.996-ko-0.9.2/src/iconv_utils.cpp\n",
            "mecab-0.996-ko-0.9.2/src/char_property.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-test-gen.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tagger.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-cost-train.cpp\n",
            "mecab-0.996-ko-0.9.2/src/learner.cpp\n",
            "mecab-0.996-ko-0.9.2/src/dictionary.cpp\n",
            "mecab-0.996-ko-0.9.2/src/lbfgs.cpp\n",
            "mecab-0.996-ko-0.9.2/src/ucs.h\n",
            "mecab-0.996-ko-0.9.2/src/writer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/learner_tagger.cpp\n",
            "mecab-0.996-ko-0.9.2/src/lbfgs.h\n",
            "mecab-0.996-ko-0.9.2/src/libmecab.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tokenizer.h\n",
            "mecab-0.996-ko-0.9.2/src/mecab.cpp\n",
            "mecab-0.996-ko-0.9.2/src/utils.cpp\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_generator.cpp\n",
            "mecab-0.996-ko-0.9.2/src/param.cpp\n",
            "mecab-0.996-ko-0.9.2/src/context_id.h\n",
            "mecab-0.996-ko-0.9.2/src/mmap.h\n",
            "mecab-0.996-ko-0.9.2/src/viterbi.h\n",
            "mecab-0.996-ko-0.9.2/src/viterbi.cpp\n",
            "mecab-0.996-ko-0.9.2/src/stream_wrapper.h\n",
            "mecab-0.996-ko-0.9.2/src/feature_index.cpp\n",
            "mecab-0.996-ko-0.9.2/src/nbest_generator.h\n",
            "mecab-0.996-ko-0.9.2/src/ucstable.h\n",
            "mecab-0.996-ko-0.9.2/src/nbest_generator.cpp\n",
            "mecab-0.996-ko-0.9.2/src/iconv_utils.h\n",
            "mecab-0.996-ko-0.9.2/src/connector.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/src/scoped_ptr.h\n",
            "mecab-0.996-ko-0.9.2/Makefile.in\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for gcc... gcc\n",
            "checking whether the C compiler works... yes\n",
            "checking for C compiler default output file name... a.out\n",
            "checking for suffix of executables... \n",
            "checking whether we are cross compiling... no\n",
            "checking for suffix of object files... o\n",
            "checking whether we are using the GNU C compiler... yes\n",
            "checking whether gcc accepts -g... yes\n",
            "checking for gcc option to accept ISO C89... none needed\n",
            "checking for style of include used by make... GNU\n",
            "checking dependency style of gcc... none\n",
            "checking for g++... g++\n",
            "checking whether we are using the GNU C++ compiler... yes\n",
            "checking whether g++ accepts -g... yes\n",
            "checking dependency style of g++... none\n",
            "checking how to run the C preprocessor... gcc -E\n",
            "checking for grep that handles long lines and -e... /bin/grep\n",
            "checking for egrep... /bin/grep -E\n",
            "checking whether gcc needs -traditional... no\n",
            "checking whether make sets $(MAKE)... (cached) yes\n",
            "checking build system type... x86_64-unknown-linux-gnu\n",
            "checking host system type... x86_64-unknown-linux-gnu\n",
            "checking how to print strings... printf\n",
            "checking for a sed that does not truncate output... /bin/sed\n",
            "checking for fgrep... /bin/grep -F\n",
            "checking for ld used by gcc... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n",
            "checking the name lister (/usr/bin/nm -B) interface... BSD nm\n",
            "checking whether ln -s works... yes\n",
            "checking the maximum length of command line arguments... 1572864\n",
            "checking whether the shell understands some XSI constructs... yes\n",
            "checking whether the shell understands \"+=\"... yes\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\n",
            "checking for /usr/bin/ld option to reload object files... -r\n",
            "checking for objdump... objdump\n",
            "checking how to recognize dependent libraries... pass_all\n",
            "checking for dlltool... dlltool\n",
            "checking how to associate runtime and link libraries... printf %s\\n\n",
            "checking for ar... ar\n",
            "checking for archiver @FILE support... @\n",
            "checking for strip... strip\n",
            "checking for ranlib... ranlib\n",
            "checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
            "checking for sysroot... no\n",
            "./configure: line 7378: /usr/bin/file: No such file or directory\n",
            "checking for mt... no\n",
            "checking if : is a manifest tool... no\n",
            "checking for ANSI C header files... yes\n",
            "checking for sys/types.h... yes\n",
            "checking for sys/stat.h... yes\n",
            "checking for stdlib.h... yes\n",
            "checking for string.h... yes\n",
            "checking for memory.h... yes\n",
            "checking for strings.h... yes\n",
            "checking for inttypes.h... yes\n",
            "checking for stdint.h... yes\n",
            "checking for unistd.h... yes\n",
            "checking for dlfcn.h... yes\n",
            "checking for objdir... .libs\n",
            "checking if gcc supports -fno-rtti -fno-exceptions... no\n",
            "checking for gcc option to produce PIC... -fPIC -DPIC\n",
            "checking if gcc PIC flag -fPIC -DPIC works... yes\n",
            "checking if gcc static flag -static works... yes\n",
            "checking if gcc supports -c -o file.o... yes\n",
            "checking if gcc supports -c -o file.o... (cached) yes\n",
            "checking whether the gcc linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking whether -lc should be explicitly linked in... no\n",
            "checking dynamic linker characteristics... GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking whether stripping libraries is possible... yes\n",
            "checking if libtool supports shared libraries... yes\n",
            "checking whether to build shared libraries... yes\n",
            "checking whether to build static libraries... yes\n",
            "checking how to run the C++ preprocessor... g++ -E\n",
            "checking for ld used by g++... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking for g++ option to produce PIC... -fPIC -DPIC\n",
            "checking if g++ PIC flag -fPIC -DPIC works... yes\n",
            "checking if g++ static flag -static works... yes\n",
            "checking if g++ supports -c -o file.o... yes\n",
            "checking if g++ supports -c -o file.o... (cached) yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking dynamic linker characteristics... (cached) GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking for library containing strerror... none required\n",
            "checking whether byte ordering is bigendian... no\n",
            "checking for ld used by GCC... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for shared library run path origin... done\n",
            "checking for iconv... yes\n",
            "checking for working iconv... yes\n",
            "checking for iconv declaration... \n",
            "         extern size_t iconv (iconv_t cd, char * *inbuf, size_t *inbytesleft, char * *outbuf, size_t *outbytesleft);\n",
            "checking for ANSI C header files... (cached) yes\n",
            "checking for an ANSI C-conforming const... yes\n",
            "checking whether byte ordering is bigendian... (cached) no\n",
            "checking for string.h... (cached) yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking fcntl.h usability... yes\n",
            "checking fcntl.h presence... yes\n",
            "checking for fcntl.h... yes\n",
            "checking for stdint.h... (cached) yes\n",
            "checking for sys/stat.h... (cached) yes\n",
            "checking sys/mman.h usability... yes\n",
            "checking sys/mman.h presence... yes\n",
            "checking for sys/mman.h... yes\n",
            "checking sys/times.h usability... yes\n",
            "checking sys/times.h presence... yes\n",
            "checking for sys/times.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking dirent.h usability... yes\n",
            "checking dirent.h presence... yes\n",
            "checking for dirent.h... yes\n",
            "checking ctype.h usability... yes\n",
            "checking ctype.h presence... yes\n",
            "checking for ctype.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking io.h usability... no\n",
            "checking io.h presence... no\n",
            "checking for io.h... no\n",
            "checking windows.h usability... no\n",
            "checking windows.h presence... no\n",
            "checking for windows.h... no\n",
            "checking pthread.h usability... yes\n",
            "checking pthread.h presence... yes\n",
            "checking for pthread.h... yes\n",
            "checking for off_t... yes\n",
            "checking for size_t... yes\n",
            "checking size of char... 1\n",
            "checking size of short... 2\n",
            "checking size of int... 4\n",
            "checking size of long... 8\n",
            "checking size of long long... 8\n",
            "checking size of size_t... 8\n",
            "checking for size_t... (cached) yes\n",
            "checking for unsigned long long int... yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking for sys/param.h... yes\n",
            "checking for getpagesize... yes\n",
            "checking for working mmap... yes\n",
            "checking for main in -lstdc++... yes\n",
            "checking for pthread_create in -lpthread... yes\n",
            "checking for pthread_join in -lpthread... yes\n",
            "checking for getenv... yes\n",
            "checking for opendir... yes\n",
            "checking whether make is GNU Make... yes\n",
            "checking if g++ supports stl <vector> (required)... yes\n",
            "checking if g++ supports stl <list> (required)... yes\n",
            "checking if g++ supports stl <map> (required)... yes\n",
            "checking if g++ supports stl <set> (required)... yes\n",
            "checking if g++ supports stl <queue> (required)... yes\n",
            "checking if g++ supports stl <functional> (required)... yes\n",
            "checking if g++ supports stl <algorithm> (required)... yes\n",
            "checking if g++ supports stl <string> (required)... yes\n",
            "checking if g++ supports stl <iostream> (required)... yes\n",
            "checking if g++ supports stl <sstream> (required)... yes\n",
            "checking if g++ supports stl <fstream> (required)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports const_cast<> (required)... yes\n",
            "checking if g++ supports static_cast<> (required)... yes\n",
            "checking if g++ supports reinterpret_cast<> (required)... yes\n",
            "checking if g++ supports namespaces (required) ... yes\n",
            "checking if g++ supports __thread (optional)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports GCC native atomic operations (optional)... yes\n",
            "checking if g++ supports OSX native atomic operations (optional)... no\n",
            "checking if g++ environment provides all required features... yes\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "config.status: creating src/Makefile\n",
            "config.status: creating src/Makefile.msvc\n",
            "config.status: creating man/Makefile\n",
            "config.status: creating doc/Makefile\n",
            "config.status: creating tests/Makefile\n",
            "config.status: creating swig/version.h\n",
            "config.status: creating mecab.iss\n",
            "config.status: creating mecab-config\n",
            "config.status: creating mecabrc\n",
            "config.status: creating config.h\n",
            "config.status: executing depfiles commands\n",
            "config.status: executing libtool commands\n",
            "config.status: executing default commands\n",
            "make  all-recursive\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making all in src\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o viterbi.lo viterbi.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp  -fPIC -DPIC -o .libs/viterbi.o\n",
            "In file included from \u001b[01m\u001b[Kviterbi.cpp:14:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kparam.h:30:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[KTarget {anonymous}::lexical_cast(Source) [with Target = std::__cxx11::basic_string<char>; Source = std::__cxx11::basic_string<char>]\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " std::string \u001b[01;35m\u001b[Klexical_cast<std::string, std::string>\u001b[m\u001b[K(std::string arg) {\n",
            "             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp -o viterbi.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tagger.lo tagger.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp  -fPIC -DPIC -o .libs/tagger.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp -o tagger.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o utils.lo utils.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp  -fPIC -DPIC -o .libs/utils.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp -o utils.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o eval.lo eval.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp  -fPIC -DPIC -o .libs/eval.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp -o eval.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o iconv_utils.lo iconv_utils.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp  -fPIC -DPIC -o .libs/iconv_utils.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp -o iconv_utils.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_rewriter.lo dictionary_rewriter.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp  -fPIC -DPIC -o .libs/dictionary_rewriter.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp -o dictionary_rewriter.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_generator.lo dictionary_generator.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp  -fPIC -DPIC -o .libs/dictionary_generator.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp -o dictionary_generator.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_compiler.lo dictionary_compiler.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp  -fPIC -DPIC -o .libs/dictionary_compiler.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp -o dictionary_compiler.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o context_id.lo context_id.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp  -fPIC -DPIC -o .libs/context_id.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp -o context_id.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o connector.lo connector.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp  -fPIC -DPIC -o .libs/connector.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp -o connector.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o nbest_generator.lo nbest_generator.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp  -fPIC -DPIC -o .libs/nbest_generator.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp -o nbest_generator.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o writer.lo writer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp  -fPIC -DPIC -o .libs/writer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp -o writer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o string_buffer.lo string_buffer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp  -fPIC -DPIC -o .libs/string_buffer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp -o string_buffer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o param.lo param.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp  -fPIC -DPIC -o .libs/param.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp -o param.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tokenizer.lo tokenizer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp  -fPIC -DPIC -o .libs/tokenizer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp -o tokenizer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o char_property.lo char_property.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp  -fPIC -DPIC -o .libs/char_property.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp -o char_property.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary.lo dictionary.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp  -fPIC -DPIC -o .libs/dictionary.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp -o dictionary.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o feature_index.lo feature_index.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp  -fPIC -DPIC -o .libs/feature_index.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp -o feature_index.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o lbfgs.lo lbfgs.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp  -fPIC -DPIC -o .libs/lbfgs.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp -o lbfgs.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner_tagger.lo learner_tagger.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp  -fPIC -DPIC -o .libs/learner_tagger.o\n",
            "\u001b[01m\u001b[Klearner_tagger.cpp:25:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[Kchar* MeCab::{anonymous}::mystrdup(const string&)\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " char *\u001b[01;35m\u001b[Kmystrdup\u001b[m\u001b[K(const std::string &str) {\n",
            "       \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp -o learner_tagger.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner.lo learner.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp  -fPIC -DPIC -o .libs/learner.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp -o learner.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o libmecab.lo libmecab.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp  -fPIC -DPIC -o .libs/libmecab.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp -o libmecab.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall  -no-undefined -version-info 2:0:0  -o libmecab.la -rpath /usr/local/lib viterbi.lo tagger.lo utils.lo eval.lo iconv_utils.lo dictionary_rewriter.lo dictionary_generator.lo dictionary_compiler.lo context_id.lo connector.lo nbest_generator.lo writer.lo string_buffer.lo param.lo tokenizer.lo char_property.lo dictionary.lo feature_index.lo lbfgs.lo learner_tagger.lo learner.lo libmecab.lo  -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++  -fPIC -DPIC -shared -nostdlib /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/7/crtbeginS.o  .libs/viterbi.o .libs/tagger.o .libs/utils.o .libs/eval.o .libs/iconv_utils.o .libs/dictionary_rewriter.o .libs/dictionary_generator.o .libs/dictionary_compiler.o .libs/context_id.o .libs/connector.o .libs/nbest_generator.o .libs/writer.o .libs/string_buffer.o .libs/param.o .libs/tokenizer.o .libs/char_property.o .libs/dictionary.o .libs/feature_index.o .libs/lbfgs.o .libs/learner_tagger.o .libs/learner.o .libs/libmecab.o   -lpthread -L/usr/lib/gcc/x86_64-linux-gnu/7 -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/gcc/x86_64-linux-gnu/7/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib/gcc/x86_64-linux-gnu/7/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crtn.o  -O3   -Wl,-soname -Wl,libmecab.so.2 -o .libs/libmecab.so.2.0.0\n",
            "libtool: link: (cd \".libs\" && rm -f \"libmecab.so.2\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so.2\")\n",
            "libtool: link: (cd \".libs\" && rm -f \"libmecab.so\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so\")\n",
            "libtool: link: ar cru .libs/libmecab.a  viterbi.o tagger.o utils.o eval.o iconv_utils.o dictionary_rewriter.o dictionary_generator.o dictionary_compiler.o context_id.o connector.o nbest_generator.o writer.o string_buffer.o param.o tokenizer.o char_property.o dictionary.o feature_index.o lbfgs.o learner_tagger.o learner.o libmecab.o\n",
            "ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "libtool: link: ranlib .libs/libmecab.a\n",
            "libtool: link: ( cd \".libs\" && rm -f \"libmecab.la\" && ln -s \"../libmecab.la\" \"libmecab.la\" )\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab.o mecab.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab mecab.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab mecab.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-index.o mecab-dict-index.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-index mecab-dict-index.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-index mecab-dict-index.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-gen.o mecab-dict-gen.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-gen mecab-dict-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-gen mecab-dict-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-cost-train.o mecab-cost-train.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-cost-train mecab-cost-train.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-cost-train mecab-cost-train.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-system-eval.o mecab-system-eval.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-system-eval mecab-system-eval.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-system-eval mecab-system-eval.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-test-gen.o mecab-test-gen.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-test-gen mecab-test-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-test-gen mecab-test-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making all in man\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making all in doc\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making all in tests\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making check in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making check in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making check in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making check in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make  check-TESTS\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 177\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 178x178\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 83\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 84x84\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 450\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 162\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3x3\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 4\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 11\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "PASS: run-dics.sh\n",
            "PASS: run-eval.sh\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "seed/model.def is not found. skipped.\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading seed/matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "reading corpus ...\n",
            "Number of sentences: 34\n",
            "Number of features:  64108\n",
            "eta:                 0.00005\n",
            "freq:                1\n",
            "eval-size:           6\n",
            "unk-eval-size:       4\n",
            "threads:             1\n",
            "charset:             EUC-JP\n",
            "C(sigma^2):          1.00000\n",
            "\n",
            "iter=0 err=1.00000 F=0.35771 target=2406.28355 diff=1.00000\n",
            "iter=1 err=0.97059 F=0.65652 target=1484.25231 diff=0.38318\n",
            "iter=2 err=0.91176 F=0.79331 target=863.32765 diff=0.41834\n",
            "iter=3 err=0.85294 F=0.89213 target=596.72480 diff=0.30881\n",
            "iter=4 err=0.61765 F=0.95467 target=336.30744 diff=0.43641\n",
            "iter=5 err=0.50000 F=0.96702 target=246.53039 diff=0.26695\n",
            "iter=6 err=0.35294 F=0.95472 target=188.93963 diff=0.23361\n",
            "iter=7 err=0.20588 F=0.99106 target=168.62665 diff=0.10751\n",
            "iter=8 err=0.05882 F=0.99777 target=158.64865 diff=0.05917\n",
            "iter=9 err=0.08824 F=0.99665 target=154.14530 diff=0.02839\n",
            "iter=10 err=0.08824 F=0.99665 target=151.94257 diff=0.01429\n",
            "iter=11 err=0.02941 F=0.99888 target=147.20825 diff=0.03116\n",
            "iter=12 err=0.00000 F=1.00000 target=147.34956 diff=0.00096\n",
            "iter=13 err=0.02941 F=0.99888 target=146.32592 diff=0.00695\n",
            "iter=14 err=0.00000 F=1.00000 target=145.77299 diff=0.00378\n",
            "iter=15 err=0.02941 F=0.99888 target=145.24641 diff=0.00361\n",
            "iter=16 err=0.00000 F=1.00000 target=144.96490 diff=0.00194\n",
            "iter=17 err=0.02941 F=0.99888 target=144.90246 diff=0.00043\n",
            "iter=18 err=0.00000 F=1.00000 target=144.75959 diff=0.00099\n",
            "iter=19 err=0.00000 F=1.00000 target=144.71727 diff=0.00029\n",
            "iter=20 err=0.00000 F=1.00000 target=144.66337 diff=0.00037\n",
            "iter=21 err=0.00000 F=1.00000 target=144.61349 diff=0.00034\n",
            "iter=22 err=0.00000 F=1.00000 target=144.62987 diff=0.00011\n",
            "iter=23 err=0.00000 F=1.00000 target=144.60060 diff=0.00020\n",
            "iter=24 err=0.00000 F=1.00000 target=144.59125 diff=0.00006\n",
            "iter=25 err=0.00000 F=1.00000 target=144.58619 diff=0.00004\n",
            "iter=26 err=0.00000 F=1.00000 target=144.58219 diff=0.00003\n",
            "iter=27 err=0.00000 F=1.00000 target=144.58059 diff=0.00001\n",
            "\n",
            "Done! writing model file ... \n",
            "model-ipadic.c1.0.f1.model is not a binary model. reopen it as text mode...\n",
            "reading seed/unk.def ... 40\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting model-ipadic.c1.0.f1.dic/left-id.def/ model-ipadic.c1.0.f1.dic/right-id.def\n",
            "emitting model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting matrix      : 100% |###########################################| \n",
            "copying seed/char.def to model-ipadic.c1.0.f1.dic/char.def\n",
            "copying seed/rewrite.def to model-ipadic.c1.0.f1.dic/rewrite.def\n",
            "copying seed/dicrc to model-ipadic.c1.0.f1.dic/dicrc\n",
            "copying seed/feature.def to model-ipadic.c1.0.f1.dic/feature.def\n",
            "copying model-ipadic.c1.0.f1.model to model-ipadic.c1.0.f1.dic/model.def\n",
            "\n",
            "done!\n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading model-ipadic.c1.0.f1.dic/matrix.def ... 346x346\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "              precision          recall         F\n",
            "LEVEL 0:    12.8959(57/442) 11.8998(57/479) 12.3779\n",
            "LEVEL 1:    12.2172(54/442) 11.2735(54/479) 11.7264\n",
            "LEVEL 2:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "LEVEL 4:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "PASS: run-cost-train.sh\n",
            "==================\n",
            "All 3 tests passed\n",
            "==================\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making install in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "test -z \"/usr/local/lib\" || /bin/mkdir -p \"/usr/local/lib\"\n",
            " /bin/bash ../libtool   --mode=install /usr/bin/install -c   libmecab.la '/usr/local/lib'\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.so.2.0.0 /usr/local/lib/libmecab.so.2.0.0\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so.2 || { rm -f libmecab.so.2 && ln -s libmecab.so.2.0.0 libmecab.so.2; }; })\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so || { rm -f libmecab.so && ln -s libmecab.so.2.0.0 libmecab.so; }; })\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.lai /usr/local/lib/libmecab.la\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.a /usr/local/lib/libmecab.a\n",
            "libtool: install: chmod 644 /usr/local/lib/libmecab.a\n",
            "libtool: install: ranlib /usr/local/lib/libmecab.a\n",
            "libtool: finish: PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin:/sbin\" ldconfig -n /usr/local/lib\n",
            "----------------------------------------------------------------------\n",
            "Libraries have been installed in:\n",
            "   /usr/local/lib\n",
            "\n",
            "If you ever happen to want to link against installed libraries\n",
            "in a given directory, LIBDIR, you must either use libtool, and\n",
            "specify the full pathname of the library, or use the `-LLIBDIR'\n",
            "flag during linking and do at least one of the following:\n",
            "   - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n",
            "     during execution\n",
            "   - add LIBDIR to the `LD_RUN_PATH' environment variable\n",
            "     during linking\n",
            "   - use the `-Wl,-rpath -Wl,LIBDIR' linker flag\n",
            "   - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n",
            "\n",
            "See any operating system documentation about shared libraries for\n",
            "more information, such as the ld(1) and ld.so(8) manual pages.\n",
            "----------------------------------------------------------------------\n",
            "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab '/usr/local/bin'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab /usr/local/bin/mecab\n",
            "test -z \"/usr/local/libexec/mecab\" || /bin/mkdir -p \"/usr/local/libexec/mecab\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab-dict-index mecab-dict-gen mecab-cost-train mecab-system-eval mecab-test-gen '/usr/local/libexec/mecab'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-index /usr/local/libexec/mecab/mecab-dict-index\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-gen /usr/local/libexec/mecab/mecab-dict-gen\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-cost-train /usr/local/libexec/mecab/mecab-cost-train\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-system-eval /usr/local/libexec/mecab/mecab-system-eval\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-test-gen /usr/local/libexec/mecab/mecab-test-gen\n",
            "test -z \"/usr/local/include\" || /bin/mkdir -p \"/usr/local/include\"\n",
            " /usr/bin/install -c -m 644 mecab.h '/usr/local/include'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making install in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "test -z \"/usr/local/share/man/man1\" || /bin/mkdir -p \"/usr/local/share/man/man1\"\n",
            " /usr/bin/install -c -m 644 mecab.1 '/usr/local/share/man/man1'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making install in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making install in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
            " /usr/bin/install -c mecab-config '/usr/local/bin'\n",
            "test -z \"/usr/local/etc\" || /bin/mkdir -p \"/usr/local/etc\"\n",
            " /usr/bin/install -c -m 644 mecabrc '/usr/local/etc'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Install mecab-ko-dic\n",
            "Install mecab-ko-dic\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 47.4M  100 47.4M    0     0  30.8M      0  0:00:01  0:00:01 --:--:-- 65.3M\n",
            "mecab-ko-dic-2.1.1-20180720/\n",
            "mecab-ko-dic-2.1.1-20180720/configure\n",
            "mecab-ko-dic-2.1.1-20180720/COPYING\n",
            "mecab-ko-dic-2.1.1-20180720/autogen.sh\n",
            "mecab-ko-dic-2.1.1-20180720/Place-station.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNG.csv\n",
            "mecab-ko-dic-2.1.1-20180720/README\n",
            "mecab-ko-dic-2.1.1-20180720/EF.csv\n",
            "mecab-ko-dic-2.1.1-20180720/MAG.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Preanalysis.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNB.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Person-actor.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VV.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Makefile.in\n",
            "mecab-ko-dic-2.1.1-20180720/matrix.def\n",
            "mecab-ko-dic-2.1.1-20180720/EC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNBC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/clean\n",
            "mecab-ko-dic-2.1.1-20180720/ChangeLog\n",
            "mecab-ko-dic-2.1.1-20180720/J.csv\n",
            "mecab-ko-dic-2.1.1-20180720/.keep\n",
            "mecab-ko-dic-2.1.1-20180720/feature.def\n",
            "mecab-ko-dic-2.1.1-20180720/Foreign.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XPN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/EP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NR.csv\n",
            "mecab-ko-dic-2.1.1-20180720/left-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/Place.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Symbol.csv\n",
            "mecab-ko-dic-2.1.1-20180720/dicrc\n",
            "mecab-ko-dic-2.1.1-20180720/NP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/ETM.csv\n",
            "mecab-ko-dic-2.1.1-20180720/IC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Place-address.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Group.csv\n",
            "mecab-ko-dic-2.1.1-20180720/model.def\n",
            "mecab-ko-dic-2.1.1-20180720/XSN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/INSTALL\n",
            "mecab-ko-dic-2.1.1-20180720/rewrite.def\n",
            "mecab-ko-dic-2.1.1-20180720/Inflect.csv\n",
            "mecab-ko-dic-2.1.1-20180720/configure.ac\n",
            "mecab-ko-dic-2.1.1-20180720/NNP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/CoinedWord.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XSV.csv\n",
            "mecab-ko-dic-2.1.1-20180720/pos-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/Makefile.am\n",
            "mecab-ko-dic-2.1.1-20180720/unk.def\n",
            "mecab-ko-dic-2.1.1-20180720/missing\n",
            "mecab-ko-dic-2.1.1-20180720/VCP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/install-sh\n",
            "mecab-ko-dic-2.1.1-20180720/Hanja.csv\n",
            "mecab-ko-dic-2.1.1-20180720/MAJ.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XSA.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Wikipedia.csv\n",
            "mecab-ko-dic-2.1.1-20180720/tools/\n",
            "mecab-ko-dic-2.1.1-20180720/tools/add-userdic.sh\n",
            "mecab-ko-dic-2.1.1-20180720/tools/mecab-bestn.sh\n",
            "mecab-ko-dic-2.1.1-20180720/tools/convert_for_using_store.sh\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/nnp.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/place.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/person.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/README.md\n",
            "mecab-ko-dic-2.1.1-20180720/NorthKorea.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VX.csv\n",
            "mecab-ko-dic-2.1.1-20180720/right-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/VA.csv\n",
            "mecab-ko-dic-2.1.1-20180720/char.def\n",
            "mecab-ko-dic-2.1.1-20180720/NEWS\n",
            "mecab-ko-dic-2.1.1-20180720/MM.csv\n",
            "mecab-ko-dic-2.1.1-20180720/ETN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/AUTHORS\n",
            "mecab-ko-dic-2.1.1-20180720/Person.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XR.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VCN.csv\n",
            "Looking in current directory for macros.\n",
            "configure.ac:2: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.  For more info, see:\n",
            "configure.ac:2: http://www.gnu.org/software/automake/manual/automake.html#Modernize-AM_005fINIT_005fAUTOMAKE-invocation\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "/tmp/mecab-ko-dic-2.1.1-20180720/missing: Unknown `--is-lightweight' option\n",
            "Try `/tmp/mecab-ko-dic-2.1.1-20180720/missing --help' for more information\n",
            "configure: WARNING: 'missing' script is too old or missing\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking whether make supports nested variables... yes\n",
            "checking for mecab-config... /usr/local/bin/mecab-config\n",
            "checking that generated files are newer than configure... done\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "/usr/local/lib\n",
            "/usr/local/libexec/mecab/mecab-dict-index -d . -o . -f UTF-8 -t UTF-8\n",
            "reading ./unk.def ... 13\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./VX.csv ... 125\n",
            "reading ./Preanalysis.csv ... 5\n",
            "reading ./NNP.csv ... 2371\n",
            "reading ./Group.csv ... 3176\n",
            "reading ./EP.csv ... 51\n",
            "reading ./J.csv ... 416\n",
            "reading ./VCN.csv ... 7\n",
            "reading ./EF.csv ... 1820\n",
            "reading ./XR.csv ... 3637\n",
            "reading ./Wikipedia.csv ... 36762\n",
            "reading ./NNB.csv ... 140\n",
            "reading ./MM.csv ... 453\n",
            "reading ./CoinedWord.csv ... 148\n",
            "reading ./Place-station.csv ... 1145\n",
            "reading ./VV.csv ... 7331\n",
            "reading ./MAG.csv ... 14242\n",
            "reading ./Hanja.csv ... 125750\n",
            "reading ./XSN.csv ... 124\n",
            "reading ./Foreign.csv ... 11690\n",
            "reading ./MAJ.csv ... 240\n",
            "reading ./IC.csv ... 1305\n",
            "reading ./EC.csv ... 2547\n",
            "reading ./NNG.csv ... 208524\n",
            "reading ./NNBC.csv ... 677\n",
            "reading ./Inflect.csv ... 44820\n",
            "reading ./VCP.csv ... 9\n",
            "reading ./XSV.csv ... 23\n",
            "reading ./ETM.csv ... 133\n",
            "reading ./Symbol.csv ... 16\n",
            "reading ./XPN.csv ... 83\n",
            "reading ./Place-address.csv ... 19301\n",
            "reading ./XSA.csv ... 19\n",
            "reading ./Place.csv ... 30303\n",
            "reading ./Person-actor.csv ... 99230\n",
            "reading ./NP.csv ... 342\n",
            "reading ./Person.csv ... 196459\n",
            "reading ./NorthKorea.csv ... 3\n",
            "reading ./ETN.csv ... 14\n",
            "reading ./VA.csv ... 2360\n",
            "reading ./NR.csv ... 482\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3822x2693\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "echo To enable dictionary, rewrite /usr/local/etc/mecabrc as \\\"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\\\"\n",
            "To enable dictionary, rewrite /usr/local/etc/mecabrc as \"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\"\n",
            "make[1]: Entering directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
            "make[1]: Nothing to be done for 'install-exec-am'.\n",
            " /bin/mkdir -p '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            " /usr/bin/install -c -m 644 model.bin matrix.bin char.bin sys.dic unk.dic left-id.def right-id.def rewrite.def pos-id.def dicrc '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            "make[1]: Leaving directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
            "Install mecab-python\n",
            "/tmp /tmp/mecab-ko-dic-2.1.1-20180720\n",
            "Cloning into 'mecab-python-0.996'...\n",
            "Unpacking objects: 100% (17/17), done.\n",
            "/tmp/mecab-ko-dic-2.1.1-20180720\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /tmp/mecab-python-0.996\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Building wheels for collected packages: mecab-python\n",
            "  Building wheel for mecab-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mecab-python: filename=mecab_python-0.996_ko_0.9.2-cp37-cp37m-linux_x86_64.whl size=141804 sha256=f03921023b00fa3a779a5415d0162e996cd0b69520c3bb30f206174cc260989e\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/7b/9f/2922869bef86c3354ae7034f7a3647c573ee1997c2dad0290a\n",
            "\u001b[33m  WARNING: Built wheel for mecab-python is invalid: Metadata 1.2 mandates PEP 440 version, but '0.996-ko-0.9.2' is not\u001b[0m\n",
            "Failed to build mecab-python\n",
            "Installing collected packages: mecab-python\n",
            "    Running setup.py install for mecab-python ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: mecab-python was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n",
            "Successfully installed mecab-python-0.996-ko-0.9.2\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "! apt-get install -y openjdk-8-jdk python3-dev\n",
        "! pip install konlpy \"tweepy<4.0.0\"\n",
        "! /bin/bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udNm_QpyEc6W",
        "outputId": "85eebfba-1b3b-45b0-dac8-426f4b106187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 88.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjUpYEhAEgb9"
      },
      "outputs": [],
      "source": [
        "# %pip install -q wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEpnj0NbEf5f",
        "outputId": "9a803cf2-38dc-4820-add3-8e6faf32c064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V1iy8jrUCQR"
      },
      "source": [
        "# Requirments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjNc9QiYxTgK"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1Fm4Dx_xTFK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import math\n",
        "import csv\n",
        "import json\n",
        "from statistics import mean\n",
        "from typing import List, Tuple, Dict, Any\n",
        "import uuid\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from easydict import EasyDict as edict\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import wandb\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchinfo import summary\n",
        "\n",
        "from transformers import ElectraModel, ElectraTokenizer, ElectraForQuestionAnswering, AutoModelForQuestionAnswering, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Xzif3OL_oAC"
      },
      "outputs": [],
      "source": [
        "for name in 'models', 'submissions':\n",
        "    os.makedirs(name, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZI1eMrCRjLY"
      },
      "source": [
        "# Set Arguments, Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3W659v9z1Vl",
        "outputId": "fd557900-f596-4f92-d499-d6a34f358b2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kobigbird_ep10_max2048_lr4e-05_531\n"
          ]
        }
      ],
      "source": [
        "args = edict({'w_project': 'test_project',\n",
        "              'w_entity': 'chohs1221',\n",
        "              'learning_rate': 4e-5,\n",
        "              'batch_size': {'train': 128,\n",
        "                             'eval': 16,\n",
        "                             'test': 128},\n",
        "              'accumulate': 64,\n",
        "              'epochs': 10,\n",
        "              'seed': 42,\n",
        "              # 'model_name': 'monologg/koelectra-base-v3-discriminator',\n",
        "              'model_name': 'monologg/kobigbird-bert-base',\n",
        "              'max_length': 2048})\n",
        "# args['NAME'] = ''f'koelectra_ep{args.epochs}_lr{args.learning_rate}_{random.randrange(0, 1024)}'\n",
        "args['NAME'] = ''f'kobigbird_ep{args.epochs}_max{args.max_length}_lr{args.learning_rate}_{random.randrange(0, 1024)}'\n",
        "print(args.NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EitWXKJmRw1b"
      },
      "source": [
        "# Initialize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51HhCeCTTDw5"
      },
      "source": [
        "## Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ualztiMEEHVy"
      },
      "outputs": [],
      "source": [
        "# wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OACaHe-L-P-c"
      },
      "outputs": [],
      "source": [
        "# wandb.init(project = args.w_project, entity = args.w_entity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kB3HPxSa-TIn"
      },
      "outputs": [],
      "source": [
        "# wandb.run.name = args.NAME\n",
        "# wandb.config.learning_rate = args.learning_rate\n",
        "# wandb.config.epochs = args.epochs\n",
        "# wandb.config.batch_size = args.batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6uJSyQCSEoa"
      },
      "source": [
        "## Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9b17md7VKba"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
        "\n",
        "seed_everything(args.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbKj9juZVV7W"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm8pjc33VKYg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "b24e367d59064ffe94d97d1f4e835de6",
            "6b7f88a143894a81ac9621c9336cafca",
            "246cb040100649f3a9ac32b79fa7f942",
            "23ab8d59fe5740c28ac7da851770b2bd",
            "59aa112555bd4c1dab32d24e440ca617",
            "9155c11f7e504ec1960db728dfc8c891",
            "6a36f70df71f4f2e9e0c40f7f1375643",
            "15dc34fe23b34991a0fd50e5e61f9e05",
            "561cd389d4f64651be67193e23b5d3d4",
            "21437da334c141858aa62b0ab736426d",
            "d64596353ab64033b4ca3fae6e30ea0d",
            "f465eaee7c7843eab536cabb989e00db",
            "637897bff4c14d759732a9ae34ffb916",
            "f111fcf852514b1db75ad523e29082ba",
            "edc2d9294cd54834abfaabc935a2edee",
            "67770d3e96c743fb833d1019bdb31fcb",
            "de8bc4c543b4434d9f39ea491e24edc4",
            "597a6252b38e4a4084669da8ef6daa63",
            "d2ee09293e9049ef93455a366c103f47",
            "aed04de878be4d0c9b9b9d5ef6d044a1",
            "e9367084c69f47778689c5caf743e1fb",
            "ea240b0b02e849bdb1242202e070cadb",
            "31a60c50686b477b90079564af4ab029",
            "26f48cd2c407461b8ad59b4bcd5fceee",
            "dc340165670a46c4b75f9bbc059927b2",
            "56ef0424070f470ca4113b264f3845d4",
            "198e761983b746cf8a66a7f8ac27c2e5",
            "6c0d29b3cc904dd88b18e31e5858c7e7",
            "b8c6933e39494d96b85dca21bbfbb424",
            "80cc74eadcda4cbfa17bdd4256fd91f7",
            "e7585555b5a5401a8a5af1d06b0bdf23",
            "12301bbd74054635815deacdbe80f02b",
            "195c318372cd472aa20b6946b9235796",
            "dabad42ff02d4e1d8820eb2286f71358",
            "6853631166d34d37b7b337562a1558e6",
            "1406045236bd420380e4605a84a226bb",
            "0505294eb5ef475ea16678cbce6ad03e",
            "4de0bc23d5f5454488c3585eaef406d2",
            "8b5d5cfcb51945ebb9bf7ab80ee6889b",
            "51c162ffb9db4d199439116c00c5d9ba",
            "6b042ec16fbb412083af4fbd3edb06b1",
            "6d426d5cdd31456393d8a2a7a7f07087",
            "140f94e240054022bfdd2a43b0a89b09",
            "77c9806439fb41c496667ff306ccb898"
          ]
        },
        "outputId": "0b5f2326-ac96-43c0-d20b-efe331c9b576"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/373 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b24e367d59064ffe94d97d1f4e835de6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/241k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f465eaee7c7843eab536cabb989e00db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/492k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31a60c50686b477b90079564af4ab029"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/169 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dabad42ff02d4e1d8820eb2286f71358"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# tokenizer = ElectraTokenizer.from_pretrained(args.model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(args.model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEQiDROgVXmg"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192,
          "referenced_widgets": [
            "71e0a80dbfc34b019e6eae53289fa723",
            "43753daef7b34e93b575f669138fbb8e",
            "cff44084b8ec443da41a82b4be42c84b",
            "1c23f5b8df7e4fe09b759d55d7150aaf",
            "fa8e61db14e949aaa9bd62219a228058",
            "157d82804a7047558845fbd24c601340",
            "9db8c42fa33b4b67b9d9728d439271bc",
            "230f49bce46f47da9a1b8cff5b3eae67",
            "94ccac2e8acb4244b220a367f363502b",
            "0f638b8296914c79ac607d307d600b9b",
            "bbf51fdaf0144da082e37a5ddb6b7248",
            "ad755d8958354184aa91b5c7489b0905",
            "ba990607d8fc4e61a1d541e5426545d7",
            "3d1878177b324e6093578a74569b8ebd",
            "9f2c9fa63abd41f0a7de87f8eddce6ce",
            "726eb28c88bb416aa61d98576e1dfdbb",
            "b9fee783a9344b26b28260c7999a2578",
            "d5613ddeab254f488f982534b5f93ea2",
            "a1dd3ca8f41345ec91273eadea3c0135",
            "c1a11a699b1247d7a450c3f63aa38c43",
            "809cd43b92a54b948ef46668e5cedcb6",
            "a096dc81231741488d465ee3fd6960c7"
          ]
        },
        "id": "ZJ-003lak8sj",
        "outputId": "194ca6eb-afd9-4a1c-d9c1-9f398d685764"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/870 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71e0a80dbfc34b019e6eae53289fa723"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/458M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad755d8958354184aa91b5c7489b0905"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at monologg/kobigbird-bert-base were not used when initializing BigBirdForQuestionAnswering: ['bert.pooler.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.pooler.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BigBirdForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BigBirdForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BigBirdForQuestionAnswering were not initialized from the model checkpoint at monologg/kobigbird-bert-base and are newly initialized: ['qa_classifier.intermediate.dense.bias', 'qa_classifier.output.LayerNorm.bias', 'qa_classifier.output.dense.bias', 'qa_classifier.qa_outputs.weight', 'qa_classifier.qa_outputs.bias', 'qa_classifier.intermediate.dense.weight', 'qa_classifier.output.LayerNorm.weight', 'qa_classifier.output.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# model = ElectraForQuestionAnswering.from_pretrained(args.model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(args.model_name)\n",
        "# summary(model, (args.batch_size.train//args.accumulate, args.max_length), dtypes=['torch.IntTensor'], device='cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OoYuu2ckzJ6"
      },
      "outputs": [],
      "source": [
        "model.cuda();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hCiOQO4VYqM"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TonS9AsIVQlv"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=args.learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlKUCHM9SUim"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SPF2-SSVoT5"
      },
      "source": [
        "## Load, Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoiHRyTOugMj"
      },
      "outputs": [],
      "source": [
        "class KoMRC:\n",
        "    def __init__(self, data, indices: List[Tuple[int, int, int]]):\n",
        "        self._data = data\n",
        "        self._indices = indices\n",
        "\n",
        "\n",
        "    # Json을 불러오는 메소드\n",
        "    @classmethod\n",
        "    def load(cls, file_path: str):\n",
        "        with open(file_path, 'r', encoding='utf-8') as fd:\n",
        "            data = json.load(fd)\n",
        "\n",
        "        indices = []\n",
        "        for d_id, document in enumerate(data['data']):\n",
        "            for p_id, paragraph in enumerate(document['paragraphs']):\n",
        "                for q_id, _ in enumerate(paragraph['qas']):\n",
        "                    indices.append((d_id, p_id, q_id))\n",
        "        \n",
        "        return cls(data, indices)\n",
        "\n",
        "\n",
        "    # 데이터 셋을 잘라내는 메소드\n",
        "    @classmethod\n",
        "    def split(cls, dataset, eval_ratio: float=.1):\n",
        "        indices = list(dataset._indices)\n",
        "        random.shuffle(indices)\n",
        "        train_indices = indices[int(len(indices) * eval_ratio):]\n",
        "        eval_indices = indices[:int(len(indices) * eval_ratio)]\n",
        "\n",
        "        return cls(dataset._data, train_indices), cls(dataset._data, eval_indices)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index: int) -> Dict[str, Any]:\n",
        "        d_id, p_id, q_id = self._indices[index]\n",
        "        paragraph = self._data['data'][d_id]['paragraphs'][p_id]\n",
        "\n",
        "        qa = paragraph['qas'][q_id]\n",
        "\n",
        "        guid = qa['guid']\n",
        "\n",
        "        context = paragraph['context'].replace('\\n', 'n').replace('\\xad', '')\n",
        "\n",
        "        question = qa['question'].replace('\\n', 'n').replace('\\xad', '')\n",
        "\n",
        "        answers = qa['answers']\n",
        "        if answers != None:\n",
        "            for a in answers:\n",
        "                a['text'] = a['text'].replace('\\n', 'n').replace('\\xad', '')\n",
        "\n",
        "\n",
        "        return {'guid': guid,\n",
        "            'context': context,\n",
        "            'question': question,\n",
        "            'answers': answers\n",
        "        }\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDu4gwv_ugKW",
        "outputId": "46fa9af0-4a22-4ea9-804a-603775220d13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Samples: 12037\n",
            "Number of Train Samples: 10834\n",
            "Number of Dev Samples: 1203\n"
          ]
        }
      ],
      "source": [
        "# dataset = KoMRC.load('./datasets2/train.json')\n",
        "dataset = KoMRC.load('/content/train.json')\n",
        "train_dataset, dev_dataset = KoMRC.split(dataset)\n",
        "print(\"Number of Samples:\", len(dataset))\n",
        "print(\"Number of Train Samples:\", len(train_dataset))\n",
        "print(\"Number of Dev Samples:\", len(dev_dataset))\n",
        "# print(dataset[0])\n",
        "# print(train_dataset[0])\n",
        "# print(dev_dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaAHVuoEVs32"
      },
      "source": [
        "## Tokenize & Tag Token Positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AluNiOayugGE"
      },
      "outputs": [],
      "source": [
        "class TokenizedKoMRC(KoMRC):\n",
        "    def __init__(self, data, indices: List[Tuple[int, int, int]]) -> None:\n",
        "        super().__init__(data, indices)\n",
        "        self._tokenizer = tokenizer\n",
        "\n",
        "\n",
        "    def _tokenize_with_position(self, sentence: str) -> List[Tuple[str, Tuple[int, int]]]:\n",
        "        position = 0\n",
        "        tokens = []\n",
        "\n",
        "        sentence_tokens = []\n",
        "        for word in sentence.split():\n",
        "            if '[UNK]' in tokenizer.tokenize(word):\n",
        "                sentence_tokens.append(word)\n",
        "            else:\n",
        "                sentence_tokens += tokenizer.tokenize(word)\n",
        "        \n",
        "        for morph in sentence_tokens:\n",
        "            if len(morph) > 2:\n",
        "                if morph[:2] == '##':\n",
        "                    morph = morph[2:]\n",
        "\n",
        "            position = sentence.find(morph, position)\n",
        "            tokens.append((morph, (position, position + len(morph))))\n",
        "            position += len(morph)\n",
        "            \n",
        "        return tokens\n",
        "            \n",
        "\n",
        "    def __getitem__(self, index: int) -> Dict[str, Any]:\n",
        "        sample = super().__getitem__(index)\n",
        "        # sample = {'guid': guid, 'context': context, 'question': question, 'answers': answers}\n",
        "\n",
        "        context, position = zip(*self._tokenize_with_position(sample['context']))\n",
        "        context, position = list(context), list(position)\n",
        "\n",
        "        question = self._tokenizer.tokenize(sample['question'])\n",
        "\n",
        "        if sample['answers'] is not None:\n",
        "            answers = []\n",
        "            for answer in sample['answers']:\n",
        "                for start, (position_start, position_end) in enumerate(position):\n",
        "                    if position_start <= answer['answer_start'] < position_end:\n",
        "                        break\n",
        "                else:\n",
        "                    print(context, answer)\n",
        "                    print(answer['guid'])\n",
        "                    print(answer['answer_start'])\n",
        "                    raise ValueError(\"No mathced start position\")\n",
        "\n",
        "                target = ''.join(answer['text'].split(' '))\n",
        "                source = ''\n",
        "                for end, morph in enumerate(context[start:], start):\n",
        "                    source += morph\n",
        "                    if target in source:\n",
        "                        break\n",
        "                else:\n",
        "                    print(context, answer)\n",
        "                    print(answer['guid'])\n",
        "                    print(answer['answer_start'])\n",
        "                    raise ValueError(\"No Matched end position\")\n",
        "\n",
        "                answers.append({'start': start, 'end': end})\n",
        "                \n",
        "        else:\n",
        "            answers = None\n",
        "        \n",
        "        return {\n",
        "            'guid': sample['guid'],\n",
        "            'context_original': sample['context'],\n",
        "            'context_position': position,\n",
        "            'question_original': sample['question'],\n",
        "            'context': context,\n",
        "            'question': question,\n",
        "            'answers': answers\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3Cu4vU1ugD2",
        "outputId": "04795b13-bc7d-4967-e527-1be1eb7f9531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Samples: 12037\n",
            "Number of Train Samples: 10834\n",
            "Number of Dev Samples: 1203\n"
          ]
        }
      ],
      "source": [
        "# dataset = TokenizedKoMRC.load('./datasets2/train.json')\n",
        "dataset = TokenizedKoMRC.load('/content/train.json')\n",
        "train_dataset, dev_dataset = TokenizedKoMRC.split(dataset)\n",
        "print(\"Number of Samples:\", len(dataset))\n",
        "print(\"Number of Train Samples:\", len(train_dataset))\n",
        "print(\"Number of Dev Samples:\", len(dev_dataset))\n",
        "# print(dataset[0])\n",
        "# print(train_dataset[0])\n",
        "# print(dev_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uTUw2GdugA8",
        "outputId": "9ed3447d-d283-4012-fac7-9efe7d0574be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['3', '만', '50', '00', '여', '명']\n"
          ]
        }
      ],
      "source": [
        "sample = dev_dataset[0]\n",
        "print(sample['context'][sample['answers'][0]['start']:sample['answers'][0]['end']+1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NQ6g-qhV_7g"
      },
      "source": [
        "## Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyN44Vg-uf-Y"
      },
      "outputs": [],
      "source": [
        "class Indexer:\n",
        "    def __init__(self, vocabs: List[str], max_length: int=args.max_length):\n",
        "        self.max_length = max_length\n",
        "        self.vocabs = vocabs\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.vocabs)\n",
        "    @property\n",
        "    def pad_id(self):\n",
        "        return tokenizer.vocab['[PAD]']\n",
        "    @property\n",
        "    def unk_id(self):\n",
        "        return tokenizer.vocab['[UNK]']\n",
        "    @property\n",
        "    def cls_id(self):\n",
        "        return tokenizer.vocab['[CLS]']\n",
        "    @property\n",
        "    def sep_id(self):\n",
        "        return tokenizer.vocab['[SEP]']\n",
        "\n",
        "\n",
        "    def sample2ids(self, sample: Dict[str, Any],) -> Dict[str, Any]:\n",
        "        context = [tokenizer.convert_tokens_to_ids(token) for token in sample['context']]\n",
        "        question = [tokenizer.convert_tokens_to_ids(token) for token in sample['question']]\n",
        "\n",
        "        context = context[:self.max_length-len(question)-3]             # Truncate context\n",
        "        \n",
        "        input_ids = [self.cls_id] + question + [self.sep_id] + context + [self.sep_id]\n",
        "        token_type_ids = [0] * (len(question) + 1) + [1] * (len(context) + 2)\n",
        "\n",
        "        if sample['answers'] is not None:\n",
        "            answer = sample['answers'][0]\n",
        "            start = min(len(question) + 2 + answer['start'], self.max_length - 1)\n",
        "            end = min(len(question) + 2 + answer['end'], self.max_length - 1)\n",
        "        else:\n",
        "            start = None\n",
        "            end = None\n",
        "\n",
        "        return {\n",
        "            'guid': sample['guid'],\n",
        "            'context': sample['context_original'],\n",
        "            'question': sample['question_original'],\n",
        "            'position': sample['context_position'],\n",
        "            'input_ids': input_ids,\n",
        "            'token_type_ids': token_type_ids,\n",
        "            'start': start,\n",
        "            'end': end\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grrjgBHWuf8H"
      },
      "outputs": [],
      "source": [
        "indexer = Indexer(list(tokenizer.vocab.keys()))\n",
        "# print(indexer.sample2ids(dev_dataset[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gLlDcdhWMVy"
      },
      "source": [
        "## Attention Mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2nGyyJLuf54"
      },
      "outputs": [],
      "source": [
        "class IndexerWrappedDataset:\n",
        "    def __init__(self, dataset: TokenizedKoMRC, indexer: Indexer) -> None:\n",
        "        self._dataset = dataset\n",
        "        self._indexer = indexer\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._dataset)\n",
        "    \n",
        "    def __getitem__(self, index: int) -> Dict[str, Any]:\n",
        "        sample = self._indexer.sample2ids(self._dataset[index])\n",
        "        sample['attention_mask'] = [1] * len(sample['input_ids'])\n",
        "\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5ee_MDquf3p"
      },
      "outputs": [],
      "source": [
        "indexed_train_dataset = IndexerWrappedDataset(train_dataset, indexer)\n",
        "indexed_dev_dataset = IndexerWrappedDataset(dev_dataset, indexer)\n",
        "\n",
        "sample = indexed_dev_dataset[0]\n",
        "# print('input_ids', sample['input_ids'])\n",
        "# print('attention_mask', sample['attention_mask'])\n",
        "# print('token_type_ids', sample['token_type_ids'])\n",
        "# print('start', sample['start'])\n",
        "# print('end', sample['end'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrnFWwNFWydX"
      },
      "source": [
        "## Collate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp4TTU5Oufy-"
      },
      "outputs": [],
      "source": [
        "class Collator:\n",
        "    def __init__(self, indexer: Indexer) -> None:\n",
        "        self._indexer = indexer\n",
        "\n",
        "\n",
        "    def __call__(self, samples: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:\n",
        "        samples = {key: [sample[key] for sample in samples] for key in samples[0]}\n",
        "\n",
        "        for key in 'start', 'end':\n",
        "            if samples[key][0] is None:\n",
        "                samples[key] = None\n",
        "            else:\n",
        "                samples[key] = torch.tensor(samples[key], dtype=torch.long)\n",
        "        \n",
        "        for key in 'input_ids', 'attention_mask', 'token_type_ids':\n",
        "            samples[key] = pad_sequence([torch.tensor(sample, dtype=torch.long) for sample in samples[key]],\n",
        "                                        batch_first=True,\n",
        "                                        padding_value=self._indexer.pad_id)\n",
        "\n",
        "        return samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNj_C_6sSwpE"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlVyogmMufwZ"
      },
      "outputs": [],
      "source": [
        "collator = Collator(indexer)\n",
        "train_loader = DataLoader(indexed_train_dataset,\n",
        "                          batch_size = args.batch_size.train // args.accumulate,\n",
        "                          shuffle = True,\n",
        "                          collate_fn = collator,\n",
        "                          num_workers = 2)\n",
        "\n",
        "dev_loader = DataLoader(indexed_dev_dataset,\n",
        "                        batch_size = args.batch_size.eval,\n",
        "                        shuffle = False,\n",
        "                        collate_fn = collator,\n",
        "                        num_workers = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lcvlUltufuC",
        "outputId": "030cc730-e13b-4992-c391-74ada8c459f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    2,  6882, 13607,  ...,     0,     0,     0],\n",
            "        [    2,  7641,  4811,  ...,     0,     0,     0],\n",
            "        [    2,  8311,  8796,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [    2,  8022,  4644,  ...,  3904,  7262,     3],\n",
            "        [    2, 17169,  4583,  ...,     0,     0,     0],\n",
            "        [    2,  8443,  7035,  ...,     0,     0,     0]])\n",
            "torch.Size([16, 1038])\n",
            "['guid', 'context', 'question', 'position', 'input_ids', 'token_type_ids', 'start', 'end', 'attention_mask']\n"
          ]
        }
      ],
      "source": [
        "batch = next(iter(dev_loader))\n",
        "print(batch['input_ids'])\n",
        "print(batch['input_ids'].shape)\n",
        "print(list(batch.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8bJH_DNRfVm"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAfQOTuPeuWN"
      },
      "source": [
        "## Empty Cuda Cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WREvLj-AARp"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1r0AJTIEHV5"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tkYfToDenKV"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rfm5X-bEufpW"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "dev_losses = []\n",
        "\n",
        "train_loss = []\n",
        "dev_loss = []\n",
        "\n",
        "loss_accumulate = 0.\n",
        "\n",
        "best_model = [-1, int(1e9)]\n",
        "\n",
        "for epoch in range(args.epochs):\n",
        "    print(\"Epoch\", epoch, '===============================================================================================================')\n",
        "\n",
        "    # Train    \n",
        "    progress_bar_train = tqdm(train_loader, desc='Train')\n",
        "    for i, batch in enumerate(progress_bar_train, 1):\n",
        "        del batch['guid'], batch['context'], batch['question'], batch['position']\n",
        "        batch = {key: value.cuda() for key, value in batch.items()}\n",
        "        \n",
        "        start = batch.pop('start')\n",
        "        end = batch.pop('end')\n",
        "        \n",
        "        output = model(**batch)\n",
        "\n",
        "        start_logits = output.start_logits\n",
        "        end_logits = output.end_logits\n",
        "        \n",
        "        loss = (F.cross_entropy(start_logits, start) + F.cross_entropy(end_logits, end)) / args.accumulate\n",
        "        loss.backward()\n",
        "\n",
        "        loss_accumulate += loss.item()\n",
        "\n",
        "        del batch, start, end, start_logits, end_logits, loss\n",
        "        \n",
        "        if i % args.accumulate == 0:\n",
        "            # clip_grad_norm_(model.parameters(), max_norm=1.)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad(set_to_none=False)\n",
        "\n",
        "            train_loss.append(loss_accumulate)\n",
        "            progress_bar_train.set_description(f\"Train - Loss: {loss_accumulate:.3f}\")\n",
        "            loss_accumulate = 0.\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        if i % int(len(train_loader) / (args.accumulate * 25)) == 0:\n",
        "            # Evaluation\n",
        "            for batch in dev_loader:\n",
        "                del batch['guid'], batch['context'], batch['question'], batch['position']\n",
        "                batch = {key: value.cuda() for key, value in batch.items()}\n",
        "\n",
        "                start = batch.pop('start')\n",
        "                end = batch.pop('end')\n",
        "                \n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    output = model(**batch)\n",
        "                \n",
        "                    start_logits = output.start_logits\n",
        "                    end_logits = output.end_logits\n",
        "                model.train()\n",
        "\n",
        "                loss = F.cross_entropy(start_logits, start) + F.cross_entropy(end_logits, end)\n",
        "\n",
        "                dev_loss.append(loss.item())\n",
        "\n",
        "                del batch, start, end, start_logits, end_logits, loss\n",
        "\n",
        "            train_losses.append(mean(train_loss))\n",
        "            dev_losses.append(mean(dev_loss))\n",
        "            train_loss = []\n",
        "            dev_loss = []\n",
        "\n",
        "            \n",
        "            if dev_losses[-1] <= best_model[1]:\n",
        "                best_model = (epoch, dev_losses[-1])\n",
        "                model.save_pretrained(f'models/{args.NAME}_{epoch}')\n",
        "                # print(f'model saved!!\\nvalid_loss: {dev_losses[-1]}')\n",
        "                \n",
        "            # wandb.log({\"train_loss\": train_losses[-1],\n",
        "                      #  \"valid_loss\": dev_losses[-1]})\n",
        "            \n",
        "\n",
        "    print(f\"Train Loss: {train_losses[-1]:.3f}\")\n",
        "    print(f\"Valid Loss: {dev_losses[-1]:.3f}\")\n",
        "    print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NeU3ogjS2LZ"
      },
      "source": [
        "## Visualize Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "3nDxYe7KufnH",
        "outputId": "7ec64a13-e458-4f1a-eedd-265871fc6890"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(dev_losses, label=\"Dev Loss\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJKrztCmXRBB"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4vjm5TrYP-S"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f9hR0qsu9Ap",
        "outputId": "98e1ac34-ec5e-4187-9e15-21749dec3989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Test Samples 4008\n"
          ]
        }
      ],
      "source": [
        "test_dataset = TokenizedKoMRC.load('/content/test.json')\n",
        "# test_dataset = TokenizedKoMRC.load('./datasets2/test.json')\n",
        "indexer_test = Indexer(list(tokenizer.vocab.keys()))\n",
        "indexed_test_dataset = IndexerWrappedDataset(test_dataset, indexer_test)\n",
        "print(\"Number of Test Samples\", len(test_dataset))\n",
        "# print(test_dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8js2FfYYJR7"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "27fPJbNLEHV6",
        "outputId": "6a180c3c-50d4-416b-9675-a8645a038f31"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-1b787aafcc9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
          ]
        }
      ],
      "source": [
        "best_model[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "F-MEvXoFv0T5",
        "outputId": "7a900c61-ab96-4b5b-d50c-03b011ed80ee"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-e83f62407969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
          ]
        }
      ],
      "source": [
        "best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nESvW3pKufkv"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForQuestionAnswering.from_pretrained(f'models/{args.NAME}_{best_model[0]}')\n",
        "model.cuda();\n",
        "# summary(model, (args.batch_size.train//args.accumulate, args.max_length), dtypes=['torch.IntTensor'], device='cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "nbM5uvjDufiJ",
        "outputId": "71c19831-441f-49d8-9192-7df6eae2d109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------1------\n",
            "Context: 1조3000억원에 달하는 사기성 기업어음(CP)을 발행해 투자자들에게 손해를 끼친 혐의 등으로 기소된 현재현 동양그룹 회장(65·사진)에게 징역 12년형이 선고됐다. 이는 역대 형사재판에 넘겨진 재벌 총수 중 두 번째로 무거운 형이다.서울중앙지법 형사합의25부(부장판사 위현석)는 17일 오후 열린 현 회장에 대한 선고 공판에서 “피해자가 4만명에 달하고 피해 금액도 유례를 찾아보기 힘든 대규모 기업범죄로 엄중한 책임을 묻지 않을 수 없다”며 이같이 선고했다. 함께 기소된 정진석 전 동양증권 사장은 징역 5년을, 김철 전 동양네트웍스 대표와 이상화 전 동양인터내셔널 대표는 각각 징역 4년과 3년6월을 선고받았다. 검찰은 앞서 현 회장에게 징역 15년형을 구형했다.재판부는 현 회장에게 적용된 1조2985억원의 사기성 CP 등 발행 혐의와 141억원대 횡령 혐의를 유죄로 판단했다. 재판부는 “피고인들은 CP 발행 당시 자력으로 만기상환하는 것은 불가능하다는 점을 알고 있었다”며 “현 회장은 그룹의 지배구조에 집착한 나머지 일반투자자를 상대로 기망적 수단과 방법을 동원해 CP와 회사채를 발행했다”고 지적했다. 이어 “이로 인해 경영과 아무런 관계가 없는 다수의 피해자가 막대한 경제적·정신적 피해를 입었다”며 “범행을 부인하며 반성하지 않고, 피해 회복을 위한 노력도 하지 않아 중형을 선고하지 않을 수 없다”고 말했다. 다만 시세조종 혐의와 6000억원대 배임 혐의에 대해서는 일부 유죄로, 회계 부정과 허위 재무제표 공시 혐의는 무죄로 판단했다.현 회장이 받은 징역 12년형은 역대 형사재판에 넘겨진 재벌 총수 중 두 번째로 높은 형이다. 최고형은 1997년 한보사태 때 정태수 전 한보그룹 회장이 받은 징역 15년형이다.\n",
            "Question: 재벌총수 중 지금까지 가장 높은 형량을 받은 사람의 이름은?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Attention type 'block_sparse' is not possible if sequence_length: 483 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-a0055a11089a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mstart_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/big_bird/modeling_big_bird.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, question_lengths, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   3110\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3111\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3112\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3113\u001b[0m         )\n\u001b[1;32m   3114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/big_bird/modeling_big_bird.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2139\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2140\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2141\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2142\u001b[0m         )\n\u001b[1;32m   2143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/big_bird/modeling_big_bird.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrescale_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2197\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2199\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper__index_select)"
          ]
        }
      ],
      "source": [
        "for idx, sample in zip(range(1, 4), indexed_train_dataset):\n",
        "    print(f'------{idx}------')\n",
        "    print('Context:', sample['context'])\n",
        "    print('Question:', sample['question'])\n",
        "    \n",
        "    input_ids, token_type_ids = [\n",
        "        torch.tensor(sample[key], dtype=torch.long, device=\"cuda\")\n",
        "        for key in (\"input_ids\", \"token_type_ids\")\n",
        "    ]\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(input_ids=input_ids[None, :], token_type_ids=token_type_ids[None, :])\n",
        "\n",
        "    start_logits = output.start_logits\n",
        "    end_logits = output.end_logits\n",
        "    start_logits.squeeze_(0), end_logits.squeeze_(0)\n",
        "    \n",
        "    start_prob = start_logits[token_type_ids.bool()][1:-1].softmax(-1)\n",
        "    end_prob = end_logits[token_type_ids.bool()][1:-1].softmax(-1)\n",
        "\n",
        "    probability = torch.triu(start_prob[:, None] @ end_prob[None, :])\n",
        "\n",
        "    index = torch.argmax(probability).item()\n",
        "    \n",
        "    start = index // len(end_prob)\n",
        "    end = index % len(end_prob)\n",
        "    \n",
        "    start_str = sample['position'][start][0]\n",
        "    end_str = sample['position'][end][1]\n",
        "\n",
        "    print('Answer:', sample['context'][start_str:end_str])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul-FlUBZY88_"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyVG3J2hu8-s"
      },
      "outputs": [],
      "source": [
        "start_visualize = []\n",
        "end_visualize = []\n",
        "\n",
        "with torch.no_grad(), open(f'submissions/{args.NAME}.csv', 'w') as fd:\n",
        "    writer = csv.writer(fd)\n",
        "    writer.writerow(['Id', 'Predicted'])\n",
        "\n",
        "    rows = []\n",
        "    c = 0\n",
        "    # for sample in tqdm(test_dataset, \"Testing\"):\n",
        "    for sample in tqdm(indexed_test_dataset, \"Testing\"):\n",
        "        input_ids, token_type_ids = [torch.tensor(sample[key], dtype=torch.long, device=\"cuda\") for key in (\"input_ids\", \"token_type_ids\")]\n",
        "        # print(sample)\n",
        "    \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            output = model(input_ids=input_ids[None, :], token_type_ids=token_type_ids[None, :])\n",
        "\n",
        "        start_logits = output.start_logits\n",
        "        end_logits = output.end_logits\n",
        "        start_logits.squeeze_(0), end_logits.squeeze_(0)\n",
        "\n",
        "        start_prob = start_logits[token_type_ids.bool()][1:-1].softmax(-1)\n",
        "        end_prob = end_logits[token_type_ids.bool()][1:-1].softmax(-1)\n",
        "\n",
        "        probability = torch.triu(start_prob[:, None] @ end_prob[None, :])\n",
        "\n",
        "        # 토큰 길이 8까지만\n",
        "        for row in range(len(start_prob) - 8):\n",
        "            probability[row] = torch.cat((probability[row][:8+row].cpu(), torch.Tensor([0] * (len(start_prob)-(8+row))).cpu()), 0)\n",
        "\n",
        "        index = torch.argmax(probability).item()\n",
        "\n",
        "        start = index // len(end_prob)\n",
        "        end = index % len(end_prob)\n",
        "        \n",
        "        # 확률 너무 낮으면 자르기\n",
        "        if start_prob[start] > 0.3 and end_prob[end] > 0.3:\n",
        "            start_str = sample['position'][start][0]\n",
        "            end_str = sample['position'][end][1]\n",
        "        else:\n",
        "            start_str = 0\n",
        "            end_str = 0\n",
        "\n",
        "        start_visualize.append((list(start_prob.cpu()), (start, end), (start_str, end_str)))\n",
        "        end_visualize.append((list(end_prob.cpu()), (start, end), (start_str, end_str)))\n",
        "        \n",
        "        rows.append([sample[\"guid\"], sample['context'][start_str:end_str]])\n",
        "\n",
        "    writer.writerows(rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tess2OmJba2K"
      },
      "source": [
        "## Visualize Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBsEFEOxbRt4"
      },
      "outputs": [],
      "source": [
        "idx = 0\n",
        "\n",
        "start_visualize = np.array(start_visualize)\n",
        "end_visualize = np.array(end_visualize)\n",
        "\n",
        "start_probalilities, token_pos, str_pos = start_visualize[:,0], start_visualize[:,1], start_visualize[:,2]\n",
        "end_probalilities, token_pos, str_pos = end_visualize[:,0], end_visualize[:,1], end_visualize[:,2]\n",
        "\n",
        "plt.plot(start_probalilities[idx], label=\"start probability\")\n",
        "plt.plot(end_probalilities[idx], label=\"end probability\")\n",
        "plt.xlabel(\"context token index\")\n",
        "plt.ylabel(\"probablilty\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print('token position:', token_pos[idx])\n",
        "print('context position:', str_pos[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0JK7qX_EHV8"
      },
      "outputs": [],
      "source": [
        "for i, (start, end) in enumerate(token_pos):\n",
        "    if end - start > 1:\n",
        "        if i > 0:\n",
        "            plt.plot(start_probalilities[i])\n",
        "            plt.plot(end_probalilities[i])\n",
        "            print(i, start, end)\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whmLTe_pEHV8"
      },
      "outputs": [],
      "source": [
        "temp = []\n",
        "h = 0\n",
        "l = 100\n",
        "for i, (start, end) in enumerate(token_pos):\n",
        "    h = max(h, end - start)\n",
        "    l = min(l ,end - start)\n",
        "    temp.append(end - start)\n",
        "plt.plot(temp)\n",
        "print(mean(temp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmylQ6jIEHV8"
      },
      "outputs": [],
      "source": [
        "mu = mean(temp)\n",
        "sigma = math.sqrt(np.var(temp))\n",
        "x = np.linspace(-100, 100, len(temp))\n",
        "g = (1 / np.sqrt(2*np.pi * sigma**2)) * np.exp(- (x-mu)**2 / (2*sigma**2))\n",
        "plt.title('Gaussian')\n",
        "plt.plot(x, g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COb77kjEEHV8"
      },
      "outputs": [],
      "source": [
        "z = [(i-mu)/sigma for i in temp]\n",
        "print(f'평균: {round(mean(z), 9)}')\n",
        "print(f'표준편차: {math.sqrt(np.var(z))}')\n",
        "print('-----90%------')\n",
        "print(mu - 1.645*sigma/math.sqrt(len(temp)))\n",
        "print(mu + 1.645*sigma/math.sqrt(len(temp)))\n",
        "print('-----95%------')\n",
        "print(mu - 1.96*sigma/math.sqrt(len(temp)))\n",
        "print(mu + 1.96*sigma/math.sqrt(len(temp)))\n",
        "print('-----99%------')\n",
        "print(mu - 2.576*sigma/math.sqrt(len(temp)))\n",
        "print(mu + 2.576*sigma/math.sqrt(len(temp)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeB2rwcapa7i"
      },
      "outputs": [],
      "source": [
        "def read_dev_klue(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        klue_dict = json.load(f)\n",
        "\n",
        "    contexts = []\n",
        "    questions = []\n",
        "    answers = []\n",
        "    for group in tqdm(klue_dict['data']):\n",
        "        for passage in group['paragraphs']:\n",
        "            context = passage['context']\n",
        "            for qa in passage['qas']:\n",
        "                question = qa['question']\n",
        "                temp_answer = []\n",
        "                for answer in qa['answers']:\n",
        "                    temp_answer.append(answer['text'])\n",
        "                if len(temp_answer) != 0: # answers의 길이가 0 == 답변할 수 없는 질문\n",
        "                    contexts.append(context)\n",
        "                    questions.append(question)\n",
        "                    answers.append(temp_answer)\n",
        "\n",
        "    return contexts, questions, answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYWUh8Xzpemv"
      },
      "outputs": [],
      "source": [
        "dev_contexts, dev_questions, dev_answers = read_dev_klue(\"/content/klue-mrc-v1.1_dev.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkg-N77drDKo"
      },
      "outputs": [],
      "source": [
        "def prediction(contexts, questions):\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "    \n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    result = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for context, question in zip(contexts, questions):\n",
        "            encodings = tokenizer(context, question, max_length=512, truncation=True,\n",
        "                                     padding=\"max_length\", return_token_type_ids=False)\n",
        "            encodings = {key: torch.tensor([val]) for key, val in encodings.items()}\n",
        "            \n",
        "            input_ids = encodings[\"input_ids\"].to(device)\n",
        "            attention_mask = encodings[\"attention_mask\"].to(device)\n",
        "            \n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
        "            token_start_index, token_end_index = start_logits.argmax(dim=-1), end_logits.argmax(dim=-1)\n",
        "            pred_ids = input_ids[0][token_start_index: token_end_index + 1]\n",
        "            pred = tokenizer.decode(pred_ids)\n",
        "            result.append(pred)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfKw4ViVrE31"
      },
      "outputs": [],
      "source": [
        "pred_answers = prediction(dev_contexts, dev_questions)\n",
        "pred_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaK2XiT6EHV8"
      },
      "outputs": [],
      "source": [
        "def em_evalutate(prediction_answers, real_answers):\n",
        "    total = len(prediction_answers)\n",
        "    exact_match = 0\n",
        "    for prediction_answer, real_answer in zip(prediction_answers, real_answers):\n",
        "        if prediction_answer in real_answer:\n",
        "            exact_match += 1\n",
        "    \n",
        "    return (exact_match/total) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7PnryhkpLlZ"
      },
      "outputs": [],
      "source": [
        "em_score = em_evalutate(pred_answers, dev_answers)\n",
        "em_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Voting"
      ],
      "metadata": {
        "id": "pG45X1wzzWhG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kh8XCicopNmC"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "1.  read_csv(비어있는 파일 생성 및 기존 결과)\n",
        "    3개의 submission으로 진행한다고 가정\n",
        "\n",
        "2.  hard vote 결과에 따라 최종 답안 결정\n",
        "    a. 2:1인 경우 2표인 답안으로 결정\n",
        "    b. 1:1:1인 경우 가장 점수가 높았던 제출본의 답안으로 결정\n",
        "'''\n",
        "\n",
        "submission1 = pd.read_csv()\n",
        "submission2 = pd.read_csv()\n",
        "submission3 = pd.read_csv()\n",
        "\n",
        "final_submission = pd.read_csv() # 프로젝트 1처럼 비어 있는 제출본 만들어서 사용\n",
        "\n",
        "ensemble_predictions = []\n",
        "\n",
        "for i in range(): # 테스트셋 크기에 따라 넣어서 사용용\n",
        "    temp_pool = {}\n",
        "    # 딕셔너리에 넣어서, 값이 있으면 그 값에 vote해주고, 없으면 새로 생성성\n",
        "    temp_pool[submission1['Predicted'][i]] = 1\n",
        "\n",
        "    if submission2['Predicted'][i] in temp_pool:\n",
        "        temp_pool[submission2['Predicted'][i]] = temp_pool[submission2['Predicted'][i]] +1\n",
        "    else:\n",
        "        temp_pool[submission2['Predicted'][i]] = 1\n",
        "\n",
        "    if submission3['Predicted'][i] in temp_pool:\n",
        "        temp_pool[submission3['Predicted'][i]] = temp_pool[submission3['Predicted'][i]] +1\n",
        "    else:\n",
        "        temp_pool[submission3['Predicted'][i]] = 1\n",
        "    \n",
        "    temp_pool = sorted(temp_pool.items(), key = lambda item: item[1], reverse=True)\n",
        "    temp_pool = list(temp_pool.keys)\n",
        "\n",
        "    # 2:1인 경우\n",
        "    if len(temp_pool) == 2: \n",
        "        ensemble_predictions.append(temp_pool[0])\n",
        "    # 1:1:1인 경우\n",
        "    elif len(temp_pool) == 3:\n",
        "        ensemble_predictions.append() # 가장 점수 높은 제출본의 답안으로 결정 ex) submission3['Predicted'][i]\n",
        "\n",
        "final_submission['Predicted'] = ensemble_predictions\n",
        "\n",
        "final_submission.to_csv('submission_ensemble.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [
        "F6uJSyQCSEoa",
        "YbKj9juZVV7W",
        "9hCiOQO4VYqM"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b24e367d59064ffe94d97d1f4e835de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b7f88a143894a81ac9621c9336cafca",
              "IPY_MODEL_246cb040100649f3a9ac32b79fa7f942",
              "IPY_MODEL_23ab8d59fe5740c28ac7da851770b2bd"
            ],
            "layout": "IPY_MODEL_59aa112555bd4c1dab32d24e440ca617"
          }
        },
        "6b7f88a143894a81ac9621c9336cafca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9155c11f7e504ec1960db728dfc8c891",
            "placeholder": "​",
            "style": "IPY_MODEL_6a36f70df71f4f2e9e0c40f7f1375643",
            "value": "Downloading: 100%"
          }
        },
        "246cb040100649f3a9ac32b79fa7f942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15dc34fe23b34991a0fd50e5e61f9e05",
            "max": 373,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_561cd389d4f64651be67193e23b5d3d4",
            "value": 373
          }
        },
        "23ab8d59fe5740c28ac7da851770b2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21437da334c141858aa62b0ab736426d",
            "placeholder": "​",
            "style": "IPY_MODEL_d64596353ab64033b4ca3fae6e30ea0d",
            "value": " 373/373 [00:00&lt;00:00, 15.3kB/s]"
          }
        },
        "59aa112555bd4c1dab32d24e440ca617": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9155c11f7e504ec1960db728dfc8c891": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a36f70df71f4f2e9e0c40f7f1375643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15dc34fe23b34991a0fd50e5e61f9e05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "561cd389d4f64651be67193e23b5d3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21437da334c141858aa62b0ab736426d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d64596353ab64033b4ca3fae6e30ea0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f465eaee7c7843eab536cabb989e00db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_637897bff4c14d759732a9ae34ffb916",
              "IPY_MODEL_f111fcf852514b1db75ad523e29082ba",
              "IPY_MODEL_edc2d9294cd54834abfaabc935a2edee"
            ],
            "layout": "IPY_MODEL_67770d3e96c743fb833d1019bdb31fcb"
          }
        },
        "637897bff4c14d759732a9ae34ffb916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de8bc4c543b4434d9f39ea491e24edc4",
            "placeholder": "​",
            "style": "IPY_MODEL_597a6252b38e4a4084669da8ef6daa63",
            "value": "Downloading: 100%"
          }
        },
        "f111fcf852514b1db75ad523e29082ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2ee09293e9049ef93455a366c103f47",
            "max": 241171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aed04de878be4d0c9b9b9d5ef6d044a1",
            "value": 241171
          }
        },
        "edc2d9294cd54834abfaabc935a2edee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9367084c69f47778689c5caf743e1fb",
            "placeholder": "​",
            "style": "IPY_MODEL_ea240b0b02e849bdb1242202e070cadb",
            "value": " 241k/241k [00:00&lt;00:00, 2.74MB/s]"
          }
        },
        "67770d3e96c743fb833d1019bdb31fcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de8bc4c543b4434d9f39ea491e24edc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "597a6252b38e4a4084669da8ef6daa63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2ee09293e9049ef93455a366c103f47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed04de878be4d0c9b9b9d5ef6d044a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9367084c69f47778689c5caf743e1fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea240b0b02e849bdb1242202e070cadb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31a60c50686b477b90079564af4ab029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26f48cd2c407461b8ad59b4bcd5fceee",
              "IPY_MODEL_dc340165670a46c4b75f9bbc059927b2",
              "IPY_MODEL_56ef0424070f470ca4113b264f3845d4"
            ],
            "layout": "IPY_MODEL_198e761983b746cf8a66a7f8ac27c2e5"
          }
        },
        "26f48cd2c407461b8ad59b4bcd5fceee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c0d29b3cc904dd88b18e31e5858c7e7",
            "placeholder": "​",
            "style": "IPY_MODEL_b8c6933e39494d96b85dca21bbfbb424",
            "value": "Downloading: 100%"
          }
        },
        "dc340165670a46c4b75f9bbc059927b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80cc74eadcda4cbfa17bdd4256fd91f7",
            "max": 491774,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7585555b5a5401a8a5af1d06b0bdf23",
            "value": 491774
          }
        },
        "56ef0424070f470ca4113b264f3845d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12301bbd74054635815deacdbe80f02b",
            "placeholder": "​",
            "style": "IPY_MODEL_195c318372cd472aa20b6946b9235796",
            "value": " 492k/492k [00:00&lt;00:00, 3.70MB/s]"
          }
        },
        "198e761983b746cf8a66a7f8ac27c2e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c0d29b3cc904dd88b18e31e5858c7e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8c6933e39494d96b85dca21bbfbb424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80cc74eadcda4cbfa17bdd4256fd91f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7585555b5a5401a8a5af1d06b0bdf23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12301bbd74054635815deacdbe80f02b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "195c318372cd472aa20b6946b9235796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dabad42ff02d4e1d8820eb2286f71358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6853631166d34d37b7b337562a1558e6",
              "IPY_MODEL_1406045236bd420380e4605a84a226bb",
              "IPY_MODEL_0505294eb5ef475ea16678cbce6ad03e"
            ],
            "layout": "IPY_MODEL_4de0bc23d5f5454488c3585eaef406d2"
          }
        },
        "6853631166d34d37b7b337562a1558e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b5d5cfcb51945ebb9bf7ab80ee6889b",
            "placeholder": "​",
            "style": "IPY_MODEL_51c162ffb9db4d199439116c00c5d9ba",
            "value": "Downloading: 100%"
          }
        },
        "1406045236bd420380e4605a84a226bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b042ec16fbb412083af4fbd3edb06b1",
            "max": 169,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d426d5cdd31456393d8a2a7a7f07087",
            "value": 169
          }
        },
        "0505294eb5ef475ea16678cbce6ad03e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_140f94e240054022bfdd2a43b0a89b09",
            "placeholder": "​",
            "style": "IPY_MODEL_77c9806439fb41c496667ff306ccb898",
            "value": " 169/169 [00:00&lt;00:00, 6.59kB/s]"
          }
        },
        "4de0bc23d5f5454488c3585eaef406d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b5d5cfcb51945ebb9bf7ab80ee6889b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51c162ffb9db4d199439116c00c5d9ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b042ec16fbb412083af4fbd3edb06b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d426d5cdd31456393d8a2a7a7f07087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "140f94e240054022bfdd2a43b0a89b09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77c9806439fb41c496667ff306ccb898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71e0a80dbfc34b019e6eae53289fa723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43753daef7b34e93b575f669138fbb8e",
              "IPY_MODEL_cff44084b8ec443da41a82b4be42c84b",
              "IPY_MODEL_1c23f5b8df7e4fe09b759d55d7150aaf"
            ],
            "layout": "IPY_MODEL_fa8e61db14e949aaa9bd62219a228058"
          }
        },
        "43753daef7b34e93b575f669138fbb8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_157d82804a7047558845fbd24c601340",
            "placeholder": "​",
            "style": "IPY_MODEL_9db8c42fa33b4b67b9d9728d439271bc",
            "value": "Downloading: 100%"
          }
        },
        "cff44084b8ec443da41a82b4be42c84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_230f49bce46f47da9a1b8cff5b3eae67",
            "max": 870,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94ccac2e8acb4244b220a367f363502b",
            "value": 870
          }
        },
        "1c23f5b8df7e4fe09b759d55d7150aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f638b8296914c79ac607d307d600b9b",
            "placeholder": "​",
            "style": "IPY_MODEL_bbf51fdaf0144da082e37a5ddb6b7248",
            "value": " 870/870 [00:00&lt;00:00, 35.4kB/s]"
          }
        },
        "fa8e61db14e949aaa9bd62219a228058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "157d82804a7047558845fbd24c601340": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9db8c42fa33b4b67b9d9728d439271bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "230f49bce46f47da9a1b8cff5b3eae67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94ccac2e8acb4244b220a367f363502b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f638b8296914c79ac607d307d600b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbf51fdaf0144da082e37a5ddb6b7248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad755d8958354184aa91b5c7489b0905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba990607d8fc4e61a1d541e5426545d7",
              "IPY_MODEL_3d1878177b324e6093578a74569b8ebd",
              "IPY_MODEL_9f2c9fa63abd41f0a7de87f8eddce6ce"
            ],
            "layout": "IPY_MODEL_726eb28c88bb416aa61d98576e1dfdbb"
          }
        },
        "ba990607d8fc4e61a1d541e5426545d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9fee783a9344b26b28260c7999a2578",
            "placeholder": "​",
            "style": "IPY_MODEL_d5613ddeab254f488f982534b5f93ea2",
            "value": "Downloading: 100%"
          }
        },
        "3d1878177b324e6093578a74569b8ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1dd3ca8f41345ec91273eadea3c0135",
            "max": 457600984,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1a11a699b1247d7a450c3f63aa38c43",
            "value": 457600984
          }
        },
        "9f2c9fa63abd41f0a7de87f8eddce6ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_809cd43b92a54b948ef46668e5cedcb6",
            "placeholder": "​",
            "style": "IPY_MODEL_a096dc81231741488d465ee3fd6960c7",
            "value": " 458M/458M [00:07&lt;00:00, 58.9MB/s]"
          }
        },
        "726eb28c88bb416aa61d98576e1dfdbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9fee783a9344b26b28260c7999a2578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5613ddeab254f488f982534b5f93ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1dd3ca8f41345ec91273eadea3c0135": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1a11a699b1247d7a450c3f63aa38c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "809cd43b92a54b948ef46668e5cedcb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a096dc81231741488d465ee3fd6960c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}